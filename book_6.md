# 6 Convergence in the Presence of Faults

The focus of this chapter is the integration of self-stabilization with other fault models, such as crash failures and Byzantine failures, both of which have been studied extensively. Crash failures are failures that cause a processor to stop operating. Algorithms that tolerate crash failures in some of the processors and achieve their goal in spite of the failures are of practical interest, since processors do crash from time to time due to power supply problems, user activity, or software problems.

In addition, software (and sometimes hardware) may contain flaws; therefore, the behavior of a faulty processor is not limited to ceasing to operate, as assumed in the crash-faults model. Obviously, the effect of software bugs cannot be determined in advance. How does one model the behavior of a faulty processor?

The Byzantine fault model assumes that the processor is controlled by an adversary that "fights" against the rest of the processors in order to prevent them from reaching their goal. A Byzantine processor can send any message at any time to each of its neighbors. Initially, algorithms that tolerate Byzantine faults were designed for flight devices that must be extremely robust. Several processors that are executing programs for the task communicate the result and decide which result is correct. Unfortunately, it is well known that, if one-third (or more) of the processors are Byzantine, it is impossible to achieve basic tasks such as consensus in distributed systems.

For example, consider a system of three processor $P_1$, $P_2$, and $P_3$ that are connected to one another. Each processor has a single input bit. The task of the non-faulty processors is to choose the same value. Moreover, when the non-faulty processors have the same input, that input must be chosen. Assume there is a distributed algorithm $\mathcal{AL}$ that achieves consensus in the presence of a single Byzantine processor in the above system. Note that if we prove that no non-stabilizing algorithm can ensure that consensus is eventually achieved (assuming the executions start in a particular initial configuration), then it is clear that no self-stabilizing algorithm for this task exists.

Consider a six-processor ring $P_1$, $P_2$, $P_3$, $P'_1$, $P'_2$, $P'_3$, where $P_1$ is connected to $P'_3$ and each $P_x$, $x \in \{1, 2, 3\}$, is identical to $P'_x$. $P_x$ and $P'_x$ run the same program as defined by $\mathcal{AL}$ for $P_x$ in the three-processor system. $P_x$ and $P'_x$ may have different input values. In particular, let the input values of the processors in the ring be 0, 0, 0, 1, 1, 1 for $P_1$, $P_2$, $P_3$, $P'_1$, $P'_2$, $P'_3$, respectively. Analyze the executions of $\mathcal{AL}$ on the ring. Note that $\mathcal{AL}$ is designed to be executed on a system with only three processors $P_1$, $P_2$ and $P_3$; we examine it only to prove the impossibility result using a ring of six processors. Furthermore, no processor is faulty in the executions examined. Thus, $P_2$ and $P_3$ must choose 0 since they both have input 0 and the information received from $P_1$ and $P'_1$ in the ring can be produced by a single Byzantine processor, namely $P_1$ in the three-processor system. On the other hand, $P'_1$ and $P'_2$ both have input 1 and the communication with $P_3$ and $P'_3$ during the execution can be produced by a Byzantine processor. Thus $P'_1$ and $P'_2$ must choose 1. The final observation is the output of $P_3$ and $P'_1$. Recall that no processor is faulty in the ring execution. Thus, both $P_3$ and $P'_1$ are non-faulty and the communication pattern between $P_2$ and $P_3$ and between $P'_1$ and $P'_2$ may be produced by a single Byzantine processor in the three-processor system that is connected to $P_3$ and $P'_1$. Thus, $P_3$ and $P'_1$ must decide on one input. The proof is complete, since we have previously proved that $P_3$ must choose 0 and $P'_1$ must choose 1.

Is this a special case? Is it perhapes possible to reach consensus when the number of processors is $3f$, where $f > 1$ is the number of Byzantine processors? The rough idea for proving the impossibility result is logically to partition the system into three clusters of processors, one of which contains all the Byzantine processors. Each cluster can be replaced by a single superprocessor that simulates the execution of the cluster (including the communication within and outside the cluster). Thus the existence of an algorithm for the case $3f$, $f > 1$, implies existence for the case $f = 1$, which in turn we proved impossible.

Now that we have proved the limitations of algorithms designed to cope with Byzantine faults, we may ask: Is it reasonable to assume that during any period of the execution less than one-third of the processors are faulty? What happens if, for a short period, more than one-third of the processors are faulty, or perhaps temporarily crashed? What happens if messages sent by non-faulty processors are lost in one instant of time? The answer to these questions is similar in flavor to the answer concerning the influence of program flaws. Such temporary violations of the assumptions can be viewed as leaving the system in an arbitrary initial state that could have been chosen by a malicious adversary and from which the algorithm resumes.

An algorithm designed to cope with both Byzantine faults and transient faults may be able to cope with severe faults that are not tolerated by an algorithm that copes with only one type of faults. Self-stabilizing algorithms that cope with ongoing faults and stabilize in spite of these faults are presented in this chapter. The existence of such algorithms demonstrates once again the generality of the self-stabilization concept. One can require stabilization whenever certain conditions hold, for example convergence to a safe configuration when less than one-third of the processors are Byzantine. To demonstrate the integration of self-stabilization with other fault concepts, we start by presenting self-stabilizing algorithms for the elegant and simple digital clock-synchronization problem. The digital clock-synchronization problem assumes a synchronous system in which the processors are activated by a global clock pulse. We follow this with the case of asynchronous systems.
