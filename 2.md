# 2 Definitions, Techniques, and Paradigms

This chapter is devoted to formalizing the distributed system, the basic assumptions, the requirements, and the complexity measures. The formal definitions are then used in the description of basic techniques and paradigms in the design of self-stabilizing algorithms and in proving their correctness.

本章致力于形式化分布式系统、基本假设、需求和复杂性度量。然后，这些形式化定义将用于描述自稳定算法设计中的基本技术和范式，并证明其正确性。

## **2.1 Definitions of the Computational Model**

The term distributed system is used to describe communication networks, multiprocessor computers, and a multitasking single computer. All the above variants of distributed systems have similar fundamental coordination requirements among the communicating entities, whether they are computers, processors, or processes. Thus an abstract model that ignores the specific setting and captures the important characteristics of a distributed system is usually employed.

分布式系统一词用于描述通信网络、多处理器计算机和多任务单计算机。上述所有分布式系统的变体在通信实体（无论是计算机、处理器还是进程）之间都有类似的基本协调需求。因此，通常采用一种**忽略具体设置**并捕捉分布式系统重要特征的**抽象模型**。

Each computer runs a program composed of executable statements. Each execution of a statement changes the content of the computer’s local memory, including the program counter. In other words, the computer changes state with each statement execution. An abstract way to model a computer that executes a program is to use the state machine model. A distributed system is modeled by a set of $n$ state machines called processors that communicate with each other. We usually denote the $i$ th processor in the system by $P_i$ . Each processor can communicate with other processors, called its neighbors. It is convenient to represent a distributed system by a communication graph in which each processor is represented by a node and every two neighboring processors are connected by a link of the communication graph.

每台计算机运行由可执行语句组成的程序。每次执行语句都会改变计算机本地内存的内容，包括程序计数器。换句话说，计算机在每次语句执行时都会改变状态。抽象地说，执行程序的计算机可以用状态机模型来表示。**分布式系统由一组称为处理器的 $n$ 个状态机组成，它们相互通信。我们通常用 $P_i$ 表示系统中的第 $i$ 个处理器。每个处理器可以与其他处理器（称为其邻居）通信。**用通信图表示分布式系统是很方便的，其中每个处理器用一个节点表示，每两个相邻的处理器通过通信图的一个链接连接。

The communication between neighboring processors can be carried out by message passing or shared memory. Communication by writing in, and reading from, the shared memory usually fits systems with processors that are geographically close together, such as multiprocessor computers or processes executed by a multitasking single-processor computer. A message-passing distributed model fits both processors that are located close to each other and wide-area distributed systems, such as communication networks.

**相邻处理器之间的通信可以通过消息传递或共享内存进行。通过写入和读取共享内存进行通信通常适用于地理位置接近的处理器系统，例如多处理器计算机或由多任务单处理器计算机执行的进程。消息传递分布式模型适用于彼此靠近的处理器和广域分布式系统，例如通信网络。**

In the message-passing model, neighbors communicate by sending and receiving messages. In asynchronous distributed systems, the speed of processors and message transmission can vary. First-in first-out (FIFO) queues are used to model asynchronous delivery of messages. A communication link is either unidirectional or bidirectional. A unidirectional communication link from processor $P_i$ to processor $P_j$ transfers messages from $P_i$ to $P_j$ . The abstraction used for such a unidirectional link is a first-in first-out (FIFO) queue $q_{i,j}$ , that contains all messages sent by a processor $P_i$ to its neighbor $P_j$ that have not yet been received. Whenever $P_i$ sends a message $m$ to $P_j$, the message is enqueued (added to the tail of the queue). $P_j$ may receive the message $m$ that is at the head of the queue; in such a case, the message $m$ is dequeued (removed from the front of the queue). The bidirectional communication link between processors $P_i$ and $P_j$ is modeled by two FIFO queues, one from $P_i$ to $P_j$ and the other from $P_j$ to $P_i$.

在消息传递模型中，相邻节点通过发送和接收消息进行通信。在异步分布式系统中，处理器的速度和消息传输的速度可以有所不同。先进先出（FIFO）队列用于模拟消息的异步传递。通信链路可以是单向的或双向的。**从处理器 $P_i$ 到处理器 $P_j$ 的单向通信链路将消息从 $P_i$ 传输到 $P_j$。用于这种单向链路的抽象是先进先出（FIFO）队列 $q_{i,j}$，它包含了所有由处理器 $P_i$ 发送给其邻居 $P_j$ 但尚未被接收的消息。**每当 $P_i$ 向 $P_j$ 发送消息 $m$ 时，该消息会被入队（添加到队列的尾部）。$P_j$ 可以接收位于队列头部的消息 $m$；在这种情况下，消息 $m$ 会被出队（从队列的前端移除）。处理器 $P_i$ 和 $P_j$ 之间的双向通信链路由两个 FIFO 队列建模，一个从 $P_i$ 到 $P_j$，另一个从 $P_j$ 到 $P_i$。

It is very convenient to identify the state of a computer or a distributed system at a given time, so that no additional information about the past of the computation is needed in order to predict the future behavior (state transitions) of the computer or the distributed system. A full description of a message passing distributed system at a particular time consists of the state of every processor and the content of every queue (messages pending in the communication links). The term *system configuration* (or *configuration*) is used for such a description. A configuration is denoted by $c = (s_1, s_2, ..., s_n, q_{1,2}, q_{1,3}, ..., q_{i,j}, ..., q_{n-1,n})$, where $s_i$, $1 ≤ i ≤ n$, is the state of $P_i$ and $q_{i,j}$, $i ≠ j$, is the queue of messages sent by $P_i$ to $P_j$ but not yet received.

在某个特定时间识别计算机或分布式系统的状态非常方便，这样就不需要额外的信息来预测计算机或分布式系统的未来行为（状态转换）。**在特定时间对消息传递分布式系统的完整描述包括每个处理器的状态和每个队列的内容（通信链路中未处理的消息）。这种描述称为系统配置（或配置）。**配置表示为 $c = (s_1, s_2, ..., s_n, q_{1,2}, q_{1,3}, ..., q_{i,j}, ..., q_{n-1,n})$，其中 $s_i$，$1 ≤ i ≤ n$，是 $P_i$ 的状态，$q_{i,j}$，$i ≠ j$，是 $P_i$ 发送给 $P_j$ 但尚未接收的消息队列。

In the shared memory model, processors communicate by the use of shared communication registers (hereafter *registers*). Processors may write in a set of registers and may read from a possibly different set of registers. The configuration of the system consists of the state of all processors and the contents of the registers. A configuration with $n$ processors and $m$ communication registers is denoted by $c = (s_1, s_2, ..., s_n; r_1, r_2, ..., r_m)$, where $s_i$, $1 ≤ i ≤ n$, is the state of $P_i$ and for $1 ≤ j ≤ m$, $r_j$ is the contents of a communication register.

**在共享内存模型中，处理器通过使用共享通信寄存器（以下简称寄存器）进行通信。处理器可以写入一组寄存器，并且可以从可能不同的一组寄存器中读取。系统的配置包括所有处理器的状态和寄存器的内容。**具有 $n$ 个处理器和 $m$ 个通信寄存器的配置表示为 $c = (s_1, s_2, ..., s_n; r_1, r_2, ..., r_m)$，其中 $s_i$，$1 ≤ i ≤ n$，是 $P_i$ 的状态，对于 $1 ≤ j ≤ m$，$r_j$ 是通信寄存器的内容。

The future state transitions of a stand-alone computer that executes a (noninteractive) program can be deterministically predicted from its current state. Note that, for a stand-alone computer, the speed of the state transitions may not be fixed (in a multitasking computer environment, the period of time for which each task is executed may change over time); nevertheless, when the tasks are totally independent, we can predict the state of each task following the $i$ th state transition of this task. The situation in distributed systems is different. Nondeterminism due to different speeds of processors and of message delivery can result in totally different state transitions of processors from identical initial states. For example, a processor waiting to receive messages from one of each of its neighbors may act differently if a message from neighbor $P_i$ arrives before a message from $P_j$ , or vice versa. In other words, scheduling of events in a distributed system influences the transitions made by the processors. The situation is even more complicated, since processors execute program statements in parallel at different rates.

执行（非交互式）程序的独立计算机的未来状态转换可以从其当前状态确定性地预测。注意，对于独立计算机，状态转换的速度可能不是固定的（在多任务计算机环境中，每个任务执行的时间段可能会随时间变化）；尽管如此，当任务完全独立时，我们可以在该任务的第 $i$ 次状态转换后预测每个任务的状态。分布式系统中的情况则不同。由于处理器和消息传递速度的不同导致的不确定性可能会导致处理器从相同的初始状态进行完全不同的状态转换。例如，一个处理器等待从每个邻居接收消息时，如果来自邻居 $P_i$ 的消息先于来自 $P_j$ 的消息到达，或者反之亦然，它可能会有不同的行为。换句话说，**分布式系统中事件的调度会影响处理器的转换。情况更加复杂，因为处理器以不同的速率并行执行程序语句。**

The interleaving model is used to reason about the behavior of the distributed system. In this model it is assumed that, at each given time, only a single processor executes a *computation step* (also called an *atomic step*). Each computation step consists of internal computation and a single communication operation: a send or receive in message passing systems and a write or read in shared memory systems. Note that a computation step may consist of local computations (e.g., subtraction of the values of two local registers of the processors) in addition to the communication operation. Without loss of generality, the time at which all the local operations between two communication operations of a processor occur is assumed to be immediately before the second communication operation. Thus, it is possible to assume that every state transition of a process is due to communication-step execution (including all local computations that follow the previous step and precede the communication operation of the computation step).

**交错模型用于推理分布式系统的行为。**在该模型中，假设在每个给定时间，只有一个处理器执行一个计算步骤（也称为原子步骤）。**每个计算步骤包括内部计算和一个通信操作：在消息传递系统中是发送或接收，在共享内存系统中是写入或读取。**注意，计算步骤除了通信操作外，还可能包括本地计算（例如，处理器的两个本地寄存器值的减法）。在不失一般性的情况下，假设处理器的两个通信操作之间的所有本地操作发生的时间是紧接在第二个通信操作之前。因此，**可以假设进程的每个状态转换都是由于通信步骤的执行**（包括所有在前一步之后和计算步骤的通信操作之前的本地计算）。

Note that a distributed system allows the processors to execute steps concurrently; however, when processors execute steps concurrently we assume that there is no influence of one step on the other. This is clearly true for send and receive operations that are executed simultaneously, because a message sent cannot be received by a receive operation that is executed at the same time. As for shared memory, it is assumed that the communication register architecture guarantees serialization: the read and write operations can be ordered in a total order such that the result of a read operation from some register is the value that was written last before this read (according to the total order) in that register.

请注意，**分布式系统允许处理器并发执行步骤**；然而，**当处理器并发执行步骤时，我们假设一个步骤不会对另一个步骤产生影响。**这对于同时执行的发送和接收操作显然是正确的，因为发送的消息不能被同时执行的接收操作接收。对于共享内存，假设通信寄存器架构保证了序列化：读和写操作可以按总顺序排列，使得从某个寄存器进行的读操作的结果是该寄存器中在此读操作之前最后写入的值（根据总顺序）。

In what follows, we use the term *step* for a computation step and we denote a step (together with the identity of the processor that executes it) by $a$. Let $c_1$ and $c_2$ be two configurations of the system, where $c_2$ is reached from $c_1$ by a single step $a$ of a processor; we denote this fact by $c_1 \xrightarrow{a} c_2$. The step $a$ is applicable to a configuration $c$ if (and only if) there exists a configuration $c’$ such that $c \xrightarrow{a} c’$. An execution $E = (c_1, a_1, c_2, a_2,···)$ (in the interleaving model) is an alternating sequence of configurations and steps such that $c_{i−1} \xrightarrow{a_{i−1}} c_i$ ($i > 1$); in other words, the configuration $c_i$ ($i > 1$) is obtained from $c_{i−1}$ by the execution of step $a_{i−1}$. For instance, if in step ai the processor $P_j$ writes the value $x$ to a register $r_k$ , then the only components that do not have identical values in $c_i$ and $c_{i+1}$ are the state of $P_j$ and the value of $r_k$ , which were changed according to $a_i$. A *fair* execution is an execution in which every step that is applicable infinitely often is executed infinitely often. In particular, if (infinitely often) a processor has a step to execute then the processor executes this step (infinitely often).

在下文中，我们使用术语步骤来表示计算步骤，并**用 $a$ 表示一个步骤**（以及执行该步骤的处理器的身份）。设 $c_1$ 和 $c_2$ 是系统的两个配置，其**中 $c_2$ 通过处理器的单个步骤 $a$ 从 $c_1$ 达到；我们用 $c_1 \xrightarrow{a} c_2$ 表示这一事实**。当且仅当存在一个配置 $c'$ 使得 $c \xrightarrow{a} c'$ 时，步骤 $a$ 才适用于配置 $c$。一个执行 $E = (c_1, a_1, c_2, a_2,···)$（在交错模型中）是**配置和步骤的交替序列**，使得 $c_{i−1} \xrightarrow{a_{i−1}} c_i$（$i > 1$）；换句话说，配置 $c_i$（$i > 1$）是通过执行步骤 $a_{i−1}$ 从 $c_{i−1}$ 获得的。例如，如果在步骤 $a_i$ 中处理器 $P_j$ 将值 $x$ 写入寄存器 $r_k$，那么在 $c_i$ 和 $c_{i+1}$ 中唯一不具有相同值的组件是 $P_j$ 的状态和 $r_k$ 的值，它们根据 $a_i$ 发生了变化。**公平执行是指每个无限次适用的步骤都被无限次执行的执行。特别地，如果（无限次）一个处理器有一个步骤要执行，那么处理器就会执行这个步骤（无限次）。**

In a message-passing system, it is possible that a message will be lost during the execution of the algorithm; the reason is unreliable communication media that may lose or corrupt messages in transit. Error-detection codes are used to identify and discard corrupted messages, and these messages can be considered lost messages. To model such systems, we extend the definition of a step to include *environment steps* of type $loss_{i,j}(m)$. The environment step $loss_{i,j}(m)$ is applicable to a configuration $c_k$ in which the queue $q_{i,j}$ contains the message $m$. The application of $loss_{i,j}(m)$ to $c_k$ results in a configuration $c_{k+1}$ in which $m$ is removed from $q_{i,j}$ , and $c_k$ and $c_{k+1}$ are identical in the rest of their components. Unlike steps executed by processors, we do not require that, in every infinite fair execution, the environment steps that are applicable infinitely often will be executed infinitely often. We do require that, in a fair execution in which a message is sent infinitely often, the message must be received infinitely often. To satisfy fairness the receive step must be executed infinitely often, while the loss step should not be executed infinitely often.

在**消息传递系统**中，算法执行过程中可能会丢失消息；原因是通信介质不可靠，可能会在传输过程中丢失或损坏消息。错误检测码用于识别和丢弃损坏的消息，这些消息可以被视为丢失的消息。为了对这种系统建模，我们扩展了步骤的定义，包括类型为 $loss_{i,j}(m)$ 的环境步骤。环境步骤 $loss_{i,j}(m)$ 适用于队列 $q_{i,j}$ 包含消息 $m$ 的配置 $c_k$。**将 $loss_{i,j}(m)$ 应用于 $c_k$ 会导致配置 $c_{k+1}$，其中 $m$ 从 $q_{i,j}$ 中移除，$c_k$ 和 $c_{k+1}$ 在其余组件中是相同的。**与处理器执行的步骤不同，**我们不要求在每个无限公平执行中，无限次适用的环境步骤将被无限次执行。我们确实要求，在一个消息无限次发送的公平执行中，该消息必须被无限次接收。**为了满足公平性，接收步骤必须被无限次执行，而丢失步骤不应被无限次执行。

Up to this stage, we have presented the class of distributed systems called asynchronous distributed systems. The experience of distributed algorithm designers is that algorithms designed for asynchronous systems perform well in communication networks and multiprocessor systems. Yet there is a class of distributed algorithms designed for synchronous distributed systems in which a global clock pulse (or simply a *pulse*) triggers a simultaneous step of every processor in the system. This class of synchronous algorithms fits multiprocessor systems in which the processors are located close to each other and can therefore be efficiently connected to a common clock pulse. Next we describe the assumptions concerning the steps of the processors in synchronous message-passing and shared-memory systems.

到目前为止，我们已经介绍了称为异步分布式系统的分布式系统类别。分布式算法设计者的经验是，为异步系统设计的算法在通信网络和多处理器系统中表现良好。然而，还有一类**为同步分布式系统设计的分布式算法**，其中**全局时钟脉冲（或简称脉冲）触发系统中每个处理器的同步步骤**。这类同步算法适用于处理器彼此靠近并且可以高效连接到公共时钟脉冲的多处理器系统。接下来，我们描述同步消息传递和共享内存系统中处理器步骤的假设。

The following actions are performed between each successive pulses of a synchronous message-passing system: the pulse triggers message send operations of every processor to every one of its neighbors, then every message is received by its destination. In the shared memory system, a pulse triggers each processor to read all the registers of its neighbors. Once every processor has finished reading, the processors can write into their registers. Thus, since all the processors execute a step simultaneously, the execution of a synchronous system $E = (c_1, c_2,···)$ is totally defined by $c_1$, the first configuration in $E$.

在同步消息传递系统的每个连续脉冲之间执行以下操作：脉冲触发每个处理器向其所有邻居发送消息操作，然后每条消息被其目的地接收。在共享内存系统中，脉冲触发每个处理器读取其所有邻居的寄存器。一旦每个处理器完成读取，处理器就可以写入它们的寄存器。因此，由于所有处理器同时执行一个步骤，**同步系统的执行 $E = (c_1, c_2,···)$ 完全由 $c_1$（即 $E$ 中的第一个配置）定义。**

## 2.2 Self-Stabilization Requirements

A self-stabilizing system can be started in any arbitrary configuration and will eventually exhibit a desired “legal” behavior.

**自稳定系统可以从任何任意配置开始，并最终表现出期望的“合法”行为。**

We define the desired legal behavior by a set of legal executions denoted $LE$. A set of legal executions is defined for a particular system and a particular task. Every system execution of a self-stabilizing system should have a suffix that appears in $LE$. For instance, when the task is mutual exclusion, the task is defined by the set of legal executions in which, in every configuration, there is at most one processor in the critical section, and in which every processor is in the critical section in an infinite number of configurations of the execution.

**我们通过一组合法执行（记为 $LE$）来定义期望的合法行为。**对于特定系统和特定任务，定义了一组合法执行。**自稳定系统的每个系统执行都应该有一个后缀出现在 $LE$ 中。**例如，当任务是互斥时，该任务由一组合法执行定义，在每个配置中，最多只有一个处理器在临界区，并且每个处理器在执行的无限多个配置中都在临界区。

A configuration $c$ is safe with regard to a task $LE$ and an algorithm if every fair execution of the algorithm that starts from $c$ belongs to $LE$.

**对于任务 $LE$ 和算法，如果从配置 $c$ 开始的算法的每个公平执行都属于 $LE$，则配置 $c$ 对该任务是安全的。**

An algorithm is *self-stabilizing* for a task $LE$ if every fair execution of the algorithm reaches a safe configuration with relation to $LE$.

**如果算法的每个公平执行都达到与任务 $LE$ 相关的安全配置，则该算法对任务 $LE$ 是自稳定的。**

## 2.3 Complexity Measures

The complexity measures used to evaluate an algorithm include time complexity and space (memory) complexity. At first glance, the attempt to define the time complexity of asynchronous systems may seem to contradict the asynchronous nature of the system. By the definition of asynchronous systems, there is no bound on the rate/speed of step-executions/message-arrivals. However, in order to evaluate and compare different asynchronous algorithms, it is convenient to use the number of *asynchronous rounds* to measure the time complexity of a particular execution. The first *asynchronous round* (or *round*) in an execution $E$ is the shortest prefix $E’$ of E such that each processor executes at least one step in $E’$. Let $E’’$ be the suffix of $E$ that follows $E’$, $E = E’E’’$. The second round of $E$ is the first round of $E’’$, and so on. The number of rounds in the execution of an algorithm is used to measure the time complexity of the algorithm.

用于评估算法的复杂度度量包括时间复杂度和空间（内存）复杂度。乍一看，试图定义异步系统的时间复杂度似乎与系统的异步性质相矛盾。根据异步系统的定义，步骤执行/消息到达的速率/速度没有上限。然而，**为了评估和比较不同的异步算法，使用异步轮数来衡量特定执行的时间复杂度是很方便的。执行 $E$ 中的第一个异步轮（或轮）是 $E$ 的最短前缀 $E'$，使得每个处理器在 $E'$ 中至少执行一步。设 $E''$ 为 $E$ 的后缀，紧随 $E'$ 之后，$E = E'E''$。$E$ 的第二轮是 $E''$ 的第一轮，依此类推。算法执行中的轮数用于衡量算法的时间复杂度。**

Intuitively, the definition of an asynchronous round nullifies the speed differences of the processors by stretching the round to be long enough to include a step (including a communication operation) of the slowest processor in this execution segment. Thus, information can be transferred through the slowest processor even if that processor resides in a node that can separate the communication graph. Moreover, if the speeds of the processors are identical and the speeds of message transmission are also identical, every asynchronous round elapses in the same constant time interval.

直观地说，**异步轮的定义通过将轮延长到足够长，以包括此执行段中最慢处理器的一步（包括通信操作），从而消除了处理器速度的差异。因此，即使该处理器位于可以分隔通信图的节点中，信息也可以通过最慢的处理器传输。**此外，如果处理器的速度相同且消息传输的速度也相同，则每个异步轮在相同的恒定时间间隔内经过。

A self-stabilizing algorithm never terminates, and processors must repeatedly communicate with their neighbors. In the shared-memory model, processors must repeatedly read the registers of their neighbors and in the message passing model, processors must continue to send and receive messages forever. The following argument is used to explain why termination cannot be achieved: assume that every processor $P_i$ has a state $s_i$ in which $P_i$ is terminated. By the self-stabilizing property of the algorithm, the system must reach a safe configuration from any initial configuration. When the system is started in a configuration $c$ in which every processor $P_i$ is in state $s_i$, no processor executes any step, and thus $c$ must be a safe configuration. Therefore the task of the algorithm is achieved when every processor $P_i$ has only one state, namely the state $s_i$. Obviously, such tasks do not require any communication between the processors and the “algorithm” that is used is not a distributed algorithm.

**自稳定算法永不终止，处理器必须反复与其邻居通信。**在共享内存模型中，处理器必须反复读取其邻居的寄存器；在消息传递模型中，处理器必须不断发送和接收消息。以下论点用于解释为什么无法实现终止：假设每个处理器 $P_i$ 有一个状态 $s_i$，其中 $P_i$ **终止**。根据算法的自稳定性，系统必须从任何初始配置达到安全配置。当系统在配置 $c$ 中启动时，其中每个处理器 $P_i$ 都处于状态 $s_i$，没有处理器执行任何步骤，因此 $c$ 必须是一个安全配置。因此，当每个处理器 $P_i$ 只有一个状态，即状态 $s_i$ 时，算法的任务就完成了。显然，这样的任务不需要处理器之间的任何通信，并且所使用的“算法”不是分布式算法。

The non-termination property can be easily identified in the code of a self-stabilizing algorithm: this code is usually a do forever loop that contains communication operations with the neighbors. For example, in the shared memory case, the code of the algorithm for a processor $P_i$ usually starts with read operations of the communication registers of $P_i$ and then local computations that are followed by write operations in the communication registers of  $P_i$. The number of steps required to execute a single iteration of such a do forever loop is $O(\triangle)$, where $\triangle$ is an upper bound on the degree (number of neighbors) of  $P_i$. In some of the proofs, it is very convenient to consider the configuration that follows at least one complete execution of an iteration of the do forever loop by every processor. Note that a processor can be started in (a state in which it is in) the middle of executing an iteration of the do forever loop. However, if $x$ is the number of steps required to complete an iteration of the do forever loop, then fewer than $2x$ steps are required to complete an iteration of the loop (from the beginning of the loop to its end) when $P_i$ is started in an arbitrary state.

自稳定算法的非终止特性可以很容易地在代码中识别出来：这段代码通常是一个包含与邻居通信操作的永久循环。例如，**在共享内存情况下，处理器 $P_i$ 的算法代码通常以读取 $P_i$ 的通信寄存器操作开始，然后是本地计算，接着是写入 $P_i$ 的通信寄存器操作。执行这样一个永久循环的单次迭代所需的步骤数是 $O(\triangle)$，其中 $\triangle$ 是 $P_i$ 的度（邻居数量）的上限。**在一些证明中，考虑每个处理器至少完整执行一次永久循环迭代后的配置是非常方便的。注意，**处理器可以在执行永久循环迭代的中间状态启动。然而，如果完成永久循环迭代所需的步骤数为 $x$，那么当 $P_i$ 从任意状态启动时，完成循环迭代（从循环的开始到结束）所需的步骤数少于 $2x$。**

For the sake of readability, we extend the definition of an asynchronous round to an asynchronous *cycle* when convenient. The first *asynchronous cycle* (or *cycle*) in an execution $E$ is the shortest prefix $E'$ of $E$ such that each processor executes at least one complete iteration of its do forever loop in $E'$. Let $E''$ be the suffix of $E$ that follows $E'$, $E = E'E''$. The second cycle of $E$ is the first cycle of $E'$, and so on.

为了便于阅读，我们在方便时将异步轮的定义扩展为异步周期。**执行 $E$ 中的第一个异步周期（或周期）是 $E$ 的最短前缀 $E'$，使得每个处理器在 $E'$ 中至少执行一次其永久循环的完整迭代。设 $E''$ 为 $E$ 的后缀，紧随 $E'$ 之后，$E = E'E''$。$E$ 的第二个周期是 $E''$ 的第一个周期，依此类推。**

Note that if the do forever iteration consists of reading the communication registers of the neighbors, local computations, and writing to the communication registers, then each cycle spans $O(\triangle)$ rounds.

请注意，如果永久循环的迭代包括读取邻居的通信寄存器、本地计算和写入通信寄存器，那么每个周期跨越 $O(\triangle)$ 轮。

The time complexity of a synchronous algorithm is the number of pulses in the execution (which corresponds to the number of rounds).

同步算法的时间复杂度是执行中的脉冲数（对应于轮数）。

The space complexity of an algorithm is the total number of (local and shared) memory bits used to implement the algorithm.

算法的空间复杂度是用于实现算法的（本地和共享）内存位的总数。

## 2.6 Example: Mutual Exclusion

Dijkstra, in his  pioneering work, presented three elegant, self-stabilizing algorithms for mutual exclusion on a ring. Dijkstra’s work is considered to be the first to introduce and demonstrate the self-stabilization concept.

Dijkstra 在他的开创性工作中，提出了三个用于环形结构互斥的优雅的自稳定算法。Dijkstra 的工作被认为是首次引入和展示自稳定概念的研究。

The algorithms presented by Dijkstra are for a system in which processors are activated by a scheduler called *central daemon*, which activates one processor at a time to execute an *aggregate step* consisting of several communication operations. For simplicity we assume that the central daemon is *fair*, activating each processor infinitely often in every infinite execution. The activated processor uses its own state and the states of its neighbors to compute its next state. In other words, the central daemon chooses one processor at a time and lets this processor read the state (that is written in the registers) of its neighbors and change the state (write the new state in the communication registers). Thus, when describing a system configuration there is no need to consider local variables that store the values read from neighbors — the state transition is made according to the values stored in the registers of the neighbors when the (single) processor is scheduled.

Dijkstra 提出的算法适用于由称为**中央守护进程的调度程序激活处理器的系统**，该调度程序**一次激活一个处理器以执行由多个通信操作组成的聚合步骤**。为简单起见，我们假设中央守护进程是公平的，在每个无限执行中无限次激活每个处理器。被激活的处理器使用自己的状态和其邻居的状态来计算其下一个状态。换句话说，中央守护进程一次选择一个处理器，并让该处理器读取其邻居的状态（写在寄存器中）并改变状态（将新状态写入通信寄存器）。因此，在描述系统配置时，无需考虑存储从邻居读取值的局部变量——状态转换是根据调度时邻居寄存器中存储的值进行的。

The system consists of $n$ processors $P_1, P_2,··· , P_n$ that are connected in a ring. Each processor has a *left* and a *right* neighbor. The left neighbor of every processor $P_i$, $1 < i ≤ n$, is  $P_{i −1}$ and the left neighbor of $P_1$ is $P_n$. Similarly, the right neighbor of every processor $P_i$ , $1 ≤ i < n$, is  $P_{i +1}$ and the right neighbor of $P_n$ is $P_1$.

系统由 $n$ 个处理器 $P_1, P_2,··· , P_n$ 组成，这些处理器连接成一个环。每个处理器都有一个左邻居和一个右邻居。每个处理器 $P_i$ 的左邻居（$1 < i ≤ n$）是 $P_{i−1}$，而 $P_1$ 的左邻居是 $P_n$。同样，每个处理器 $P_i$ 的右邻居（$1 ≤ i < n$）是 $P_{i+1}$，而 $P_n$ 的右邻居是 $P_1$。

Each processor $P_i$ has a variable $x_i$ that stores an integer value that is no smaller than 0 and no larger than $n$. The transition functions of the processors $P_2,··· , P_n$ are identical, while the transition function of $P_1$ is distinct. We call $P_1$ the special processor. The transition functions (or programs) of $P_1$ and the other processors $P_i$ ($2 ≤ i ≤ n$) appear in figure 2.2.

每个处理器 $P_i$ 有一个变量 $x_i$，该变量存储一个不小于 0 且不大于 $n$ 的整数。处理器 $P_2,··· , P_n$ 的转换函数是相同的，而 $P_1$ 的转换函数是不同的。我们称 $P_1$ 为特殊处理器。$P_1$ 和其他处理器 $P_i$（$2 ≤ i ≤ n$）的转换函数（或程序）如图 2.2 所示。

![figure_2.2](images/figure_2.2.png)

A configuration of the system is a vector of $n$ integer values, one value for each $x$ variable. A computation step of a processor $P_i$ consists of reading the $x$ variable of the left neighbor and using the value obtained together with the value of xi to compute a new value for $x_i$. At any given time, only a single processor is executing a computation step. A processor $P_i$ can change its state in a particular configuration $c$ if the next computation step of $P_i$ (when started in $c$) changes the value of $x_i$; i.e., $x_i \neq x_{i−1}$ in $c$, or $x_1 = x_n$ in $c$.

系统的配置是一个包含 $n$ 个整数值的向量，每个 $x$ 变量对应一个值。处理器 $P_i$ 的计算步骤包括读取左邻居的 $x$ 变量，并使用获得的值与 $x_i$ 的值一起计算 $x_i$ 的新值。**在任何给定时间，只有一个处理器在执行计算步骤。**如果处理器 $P_i$ 的下一个计算步骤（从配置 $c$ 开始时）改变了 $x_i$ 的值，则处理器 $P_i$ 可以在特定配置 $c$ 中改变其状态；即在配置 $c$ 中，$x_i \neq x_{i−1}$，或 $x_1 = x_n$。

The task $ME$ is defined by the set of all configuration sequences in which exactly one processor can change its state in any configuration and every processor can change its state in infinitely many configurations in every sequence in $ME$. Note that this definition differs from the traditional definition of mutual exclusion that allows processors to be in the reminder section (possibly forever) as long as they do not try to enter the critical section.

**任务 $ME$ 的定义是：它是满足这样一些要求的，所有的配置序列的集合，其中在任何配置中恰好有一个处理器可以改变其状态，并且在 $ME$ 中的每个序列中，每个处理器都可以在无限多个配置中改变其状态。**请注意，这一定义不同于传统的互斥定义，传统定义允许处理器在提醒区（可能永远）中，只要它们不尝试进入临界区。

A safe configuration for $ME$ and Dijkstra’s algorithm (figure 2.2) is a configuration in which all the $x$ variables have the same value. This is only one example of a safe configuration, but sufficient for what we need. The next lemma proves that, indeed, every fair execution that starts with such a safe configuration belongs to $ME$.

对于任务 $ME$ 和 Dijkstra 的算法（图 2.2），一个安全配置是所有 $x$ 变量具有相同值的配置。这只是一个安全配置的例子，但足以满足我们的需要。下一个引理证明，确实，每个从这种安全配置开始的公平执行都属于 $ME$。

> LEMMA 2.2: A configuration $c$ in which all the $x$ variables have the same value is a safe configuration for $ME$ and Dijkstra’s algorithm.
>
> **引理 2.2**：在配置 $c$ 中，如果所有 $x$ 变量具有相同的值，则该配置对于 $ME$ 和 Dijkstra 算法来说是安全的配置。

Proof: Clearly the only processor $P_i$ that is able to change the value of $x_i$ in $c$ is $P_1$. $P_1$ is activated infinitely often in every fair execution that starts in c. Once $P_1$ is activated, $P_1$ assigns $x_1$ a value that does not exist in any other variable. Let $c_1$ be the configuration that immediately follows the assignment of this new value in $x_1$. Clearly, $P_1$ cannot change the value of $x_1$ until $x_n$ holds the new value as well. Every other processor $P_i$ cannot change the value of $x_i$ unless $x_{i−1} \neq x_i$. Thus, the only processor $P_i$ that can change the value of $x_i$ is $P_2$. $P_2$ is activated infinitely often in every fair execution, and in particular it is activated infinitely often following $c_1$ of every fair execution. Let $c_2$ be the configuration reached immediately after $P_2$ changes the value of $x_2$. In $c_2$, it holds that $x_1 = x_2$, $x_2 \neq x_3$, and $x_3 = x_4 = ··· = x_n$. Thus, the only processor that is able to change a state is $P_3$. In general, in $c_i$ , $1 ≤ i < n$, it holds that $x_1 = x_2 = ··· = x_i$, $x_i \neq x_{i+1}$, and $x_{i+1} = x_{i+2} = ··· = x_n$. Thus, the only processor that is able to change the value of its variable is  $P_{i +1}$. Therefore, in $c_{n−1}$, only $P_n$ is able to change the value of its variable and, once it is activated, a configuration $c_n$ is reached in which the values of all the variables are the same. Note that in every execution that starts in $c$ and ends in $c_n$ exactly one processor is able to change the value of its variable and each processor changes the value of its variable exactly once.

Exactly the same arguments can be applied to $c_n$; thus it is clear that, in every fair execution, every processor changes the value of its variable infinitely often and, in every execution, there is exactly one processor that can change its state. (End)

证明：

显然，在配置 $c$ 中，唯一能够改变 $x_i$ 值的处理器 $P_i$ 是 $P_1$。在每个从 $c$ 开始的公平执行中，$P_1$ 被无限次激活。一旦 $P_1$ 被激活，$P_1$ 会为 $x_1$ 分配一个在其他变量中不存在的值。设 $c_1$ 为在 $x_1$ 分配新值后立即跟随的配置。显然，$P_1$ 不能改变 $x_1$ 的值，直到 $x_n$ 也持有新值。

每个其他处理器 $P_i$ 不能改变 $x_i$ 的值，除非 $x_{i−1} \neq x_i$。因此，唯一能够改变 $x_i$ 值的处理器 $P_i$ 是 $P_2$。在每个公平执行中，$P_2$ 被无限次激活，特别是在每个公平执行的 $c_1$ 之后无限次激活。

设 $c_2$ 为 $P_2$ 改变 $x_2$ 值后立即达到的配置。在 $c_2$ 中，$x_1 = x_2$，$x_2 \neq x_3$，并且 $x_3 = x_4 = ··· = x_n$。因此，唯一能够改变状态的处理器是 $P_3$。

一般来说，在 $c_i$ 中，$1 ≤ i < n$，有 $x_1 = x_2 = ··· = x_i$，$x_i \neq x_{i+1}$，并且 $x_{i+1} = x_{i+2} = ··· = x_n$。因此，唯一能够改变其变量值的处理器是 $P_{i +1}$。

因此，在 $c_{n−1}$ 中，只有 $P_n$ 能够改变其变量的值，一旦它被激活，就会达到一个配置 $c_n$，其中所有变量的值都相同。注意，在每个从 $c$ 开始并以 $c_n$ 结束的执行中，只有一个处理器能够改变其变量的值，并且每个处理器恰好改变其变量的值一次。

完全相同的论点可以应用于 $c_n$；因此显然，在每个公平执行中，每个处理器无限次地改变其变量的值，并且在每个执行中，恰好有一个处理器能够改变其状态。（完）

To prove that Dijkstra’s algorithm is self-stabilizing for $ME$, we need to show that, in every fair execution, a safe configuration relative to $ME$ is reached after a finite number of rounds. We first observe that, in any possible configuration, at least one possible value for the $x$ variables does not exist. In fact, the observation that in any configuration at least one value is missing is used in what follows. We call this concept the *missing value* or *missing label concept*.

为了证明 Dijkstra 算法对 $ME$ 是自稳定的，我们需要证明在每个公平执行中，相对于 $ME$ 的安全配置在有限轮次后达到。我们首先观察到，**在任何可能的配置中，至少有一个 $x$ 变量的可能值不存在。**事实上，接下来将使用这一观察，即在任何配置中至少缺少一个值。我们称这一概念为缺失值或缺失标签概念。

> LEMMA 2.3: For every possible configuration $c$, there exists at least one integer $0 ≤ j ≤ n$ such that for every $1 ≤ i ≤ n$, $x_i \neq j$ in $c$.
>
> **引理 2.3**：对于每一个可能的配置 $c$，存在至少一个整数 $0 ≤ j ≤ n$，使得对于每一个 $1 ≤ i ≤ n$，在配置 $c$ 中 $x_i \neq j$。

Proof: There are at most $n$ distinct values in the $x$ variables in $c$, a distinct value for each processor $P_i$. There are $n + 1$ possible values that can be stored in each of the $x$ variables. Thus, an integer $j$ must exist that does not appear in any $x_i$. (End)

证明

在配置 $c$ 中，$x$ 变量中最多有 $n$ 个不同的值，每个处理器 $P_i$ 对应一个不同的值。每个 $x$ 变量可以存储 $n + 1$ 个可能的值。因此，必须存在一个整数 $j$，它不会出现在任何 $x_i$ 中。（完）

The next observation is also simple, claiming that the special processor $P_1$ changes the value of $x_1$ infinitely often in every fair execution.

下一个观察也很简单，声称**特殊处理器 $P_1$ 在每个公平执行中无限次地改变 $x_1$ 的值**。

> LEMMA 2.4: For every possible configuration $c$, in every fair execution that starts in $c$, the special processor $P_1$ changes the value of $x_1$ at least once in every $n$ rounds.
>
> **引理 2.4**：对于每一个可能的配置 $c$，在每个从 $c$ 开始的公平执行中，特殊处理器 $P_1$ 在每 $n$ 轮中至少改变一次 $x_1$ 的值。

Proof: Assume that there exists a configuration $c$ and a fair execution that starts in $c$ and in which $P_1$ does not change the value of $x_1$ during the first $n$ rounds. Let $c_2$ be the configuration that immediately follows the first time $P_2$ executes a computation step during the first round. Clearly, $x_1 = x_2$ in $c_2$ and in every configuration that follows $c_2$ in the next $n − 1$ rounds. Let $c_3$ be the configuration that immediately follows the first time $P_3$ executes a computation step during the second round. It holds in $c_3$ that $x_1 = x_2 = x_3$. The same argument repeats itself until we arrive at the configuration $c_n$, which is reached in the ($n − 1$) th round and in which $x_1 = x_2 =···= x_n$. In the $n$ th round, $P_1$ is activated and changes the value of $x_1$, a contradiction. (End)

证明：

**假设**存在一个配置 $c$ 和一个从 $c$ 开始的公平执行，在该执行中 $P_1$ 在前 $n$ 轮中没有改变 $x_1$ 的值。

- 设 $c_2$ 为 $P_2$ 在第一轮中第一次执行计算步骤后立即跟随的配置。显然，在 $c_2$ 中 $x_1 = x_2$，并且在接下来的 $n − 1$ 轮中每个跟随 $c_2$ 的配置中也是如此。
- 设 $c_3$ 为 $P_3$ 在第二轮中第一次执行计算步骤后立即跟随的配置。在 $c_3$ 中，$x_1 = x_2 = x_3$。
- 同样的论点重复，直到我们到达配置 $c_n$，该配置在第 ($n − 1$) 轮中达到，并且在该配置中 $x_1 = x_2 =···= x_n$。

在第 $n$ 轮中，$P_1$ 被激活并改变 $x_1$ 的值，这与假设矛盾。（完）

**We are now ready to prove the main theorem.**

我们现在准备证明主要定理。

> THEOREM 2.1: For every possible configuration $c$, every fair execution that starts in $c$ reaches a safe configuration with relation to $ME$ within $O(n^2)$ rounds.
>
> **定理 2.1**：对于每一个可能的配置 $c$，每个从 $c$ 开始的公平执行在 $O(n^2)$ 轮内达到相对于 $ME$ 的安全配置。

Proof: In accordance with lemma 2.3, for every possible configuration $c$ there exists at least one integer $0 ≤ j ≤ n$ such that, for every $1 ≤ i ≤ n$, $x_i \neq j$ in $c$. In accordance with lemma 2.4, for every possible configuration $c$, in every fair execution that starts in $c$, the special processor $P_1$ changes the value of $x_1$ in every $n$ rounds. Every time $P_1$ changes the value of $x_1$, $P_1$ increments the value of $x_1$ modulo $n + 1$. Thus, it must hold that every possible value, and in particular the value $j$, is assigned to $x_1$ during any fair execution that starts in $c$. Let $c_j$ be the configuration that immediately follows the first assignment of $j$ in $x_1$. Every processor $P_i$ $2 ≤ i ≤ n$ copies the value of $x_{i−1}$ to $x_i$ . Thus, it holds for $1 ≤ i ≤ n$ that $x_i \neq j$ in every configuration that follows $c$ and precedes $c_j$; it also holds that in $c_j$ , the only $x$ variable that holds the value $j$ is $x_1$. $P_1$ does not change the value of $x_1$ until $x_n = j$. The only possible sequence of changes of the values of the $x$ variables to the value $j$ is: $P_2$ changes $x_2$ to the value of $x_1$ (which is $j$), then $P_3$ changes the value of $x_3$ to $j$ and so on until $P_n$ changes the value of $x_n$ to $j$. Only at this stage is $P_1$ able to change value again (following $c_j$). Let $c_n$ be the configuration reached following the assignment of $x_n := j$. $c_n$ is a safe configuration.

In accordance with lemma 2.4, $P_1$ must assign $j$ to $x_1$ in every $n^2$ rounds. Thus a safe configuration must be reached in $n^2 + n$ rounds. (End)

证明：

根据引理 2.3，对于每一个可能的配置 $c$，存在至少一个整数 $0 ≤ j ≤ n$，使得对于每一个 $1 ≤ i ≤ n$，在配置 $c$ 中 $x_i \neq j$。

根据引理 2.4，对于每一个可能的配置 $c$，在每个从 $c$ 开始的公平执行中，特殊处理器 $P_1$ 在每 $n$ 轮中改变一次 $x_1$ 的值。

每次 $P_1$ 改变 $x_1$ 的值时，$P_1$ 将 $x_1$ 的值按模 $n + 1$ 增加。

因此，在从 $c$ 开始的任何公平执行中，$x_1$ 必定会被分配到每一个可能的值，特别是值 $j$。设 $c_j$ 为 $x_1$ 首次分配值 $j$ 后立即跟随的配置。

每个处理器 $P_i$ ($2 ≤ i ≤ n$) 将 $x_{i−1}$ 的值复制到 $x_i$。因此，对于 $1 ≤ i ≤ n$，在每个跟随 $c$ 并先于 $c_j$ 的配置中，$x_i \neq j$；在 $c_j$ 中，唯一持有值 $j$ 的 $x$ 变量是 $x_1$。$P_1$ 不会改变 $x_1$ 的值，直到 $x_n = j$。

唯一可能的将 $x$ 变量的值改变为 $j$ 的序列是：$P_2$ 将 $x_2$ 的值改变为 $x_1$ 的值（即 $j$），然后 $P_3$ 将 $x_3$ 的值改变为 $j$，依此类推，直到 $P_n$ 将 $x_n$ 的值改变为 $j$。只有在这个阶段，$P_1$ 才能再次改变值（跟随 $c_j$）。设 $c_n$ 为 $x_n := j$ 分配后的配置。$c_n$ 是一个安全配置。

根据引理 2.4，$P_1$ 必须在每 $n^2$ 轮中将 $j$ 分配给 $x_1$。因此，安全配置必须在 $n^2 + n$ 轮内达到。（完）

In fact, Dijkstra’s algorithm stabilizes when the number of possible values for the $x$ variable is $n$. The reason is that, if no possible value is missing in the first configuration, then $x_1$ has a distinct value; thus, stabilization is guaranteed. Otherwise, at least one possible value is missing in the first configuration and theorem 2.1 holds.

事实上，当 $x$ 变量的可能值数量为 $n$ 时，Dijkstra 算法会稳定下来。原因是，如果在初始配置中没有缺失的可能值，那么 $x_1$ 就有一个独特的值；因此，稳定性是有保证的。否则，在初始配置中至少缺少一个可能值，并且定理 2.1 成立。

Moreover, a similar argument holds when the number of possible values for the x variables is $n − 1$. In this case, a configuration must be reached in which $x_n = x_1$ (just before the first time $P_1$ changes the value of $x_1$). Call this configuration $c$. If in c every processor $P_i$, $1 ≤ i ≤ n − 1$, does not hold a distinct value in xi , then a missing value $j$ must exist and the stabilization is proved by a proof similar to that of theorem 2.1. Otherwise, each $P_i$, $1 ≤ i ≤ n − 1$, holds a distinct value in $c$. Let $j'$ be the value of $x_1$ in $c$ and consider the first configuration $c'$ that follows c and in which $P_1$ is able to change the value of $x_1$. Consider the following three cases for the first computation step that follows $c$. Case 1: a processor $P_i$, $2 ≤ i ≤ n − 1$, copies the value of $x_{i−1}$ to $x_i$ and, at the same time, eliminates the distinct value stored in xi from the system. Case 2: $P_n$ copies the distinct value of $x_{n−1}$ to $x_n$, leaving $x_1$ with a distinct value. Case 3: $P_1$ changes the value of $x_1$ to $k = (j'+1) \mod (n−1)$; thus, the only x variable that holds $j'$ is $x_n$. However, $P_n$ must copy the value $k$ within the next $n$ rounds (before $P_1$ changes the value of $x_1$ again), eliminating $j'$ from the system.

此外，当 $x$ 变量的可能值数量为 $n − 1$ 时，类似的论点也成立。在这种情况下，必须达到一个配置，其中 $x_n = x_1$（就在 $P_1$ 第一次改变 $x_1$ 的值之前）。称此配置为 $c$。如果在 $c$ 中，每个处理器 $P_i$（$1 ≤ i ≤ n − 1$）在 $x_i$ 中没有持有一个独特的值，那么必须存在一个缺失值 $j$，并且通过类似于定理 2.1 的证明可以证明稳定性。否则，每个 $P_i$（$1 ≤ i ≤ n − 1$）在 $c$ 中持有一个独特的值。设 $j'$ 为 $c$ 中 $x_1$ 的值，并考虑紧随 $c$ 之后的第一个配置 $c'$，在该配置中 $P_1$ 能够改变 $x_1$ 的值。考虑以下三种情况，作为紧随 $c$ 之后的第一个计算步骤。

情况 1：处理器 $P_i$（$2 ≤ i ≤ n − 1$）将 $x_{i−1}$ 的值复制到 $x_i$，同时从系统中消除存储在 $x_i$ 中的独特值。

情况 2：$P_n$ 将 $x_{n−1}$ 的独特值复制到 $x_n$，使 $x_1$ 保持一个独特的值。

情况 3：$P_1$ 将 $x_1$ 的值改变为 $k = (j'+1) \mod (n−1)$；因此，唯一持有 $j'$ 的 $x$ 变量是 $x_n$。然而，$P_n$ 必须在接下来的 $n$ 轮内复制值 $k$（在 $P_1$ 再次改变 $x_1$ 的值之前），从系统中消除 $j'$。

Will Dijkstra’s algorithm stabilize when the number of possible values for the $x$ variables is $n − 2$ ? Let $c$ = {0, 0, 2, 1, 0} be a system configuration. An execution that starts in $c$ and repeatedly activates $P_1$, $P_5$, $P_4$, $P_3$, $P_2$, in this order, does not reach a safe configuration:

Dijkstra 算法是否会在 $x$ 变量的可能值数量为 $n − 2$ 时稳定？设 $c$ = {0, 0, 2, 1, 0} 为一个系统配置。从 $c$ 开始并按顺序重复激活 $P_1$、$P_5$、$P_4$、$P_3$、$P_2$ 的执行不会达到安全配置：

{0, 0, 2, 1, 0}→{1, 0, 2, 1, 0}→{1, 0, 2, 1, 1}→{1, 0, 2, 2, 1}→{1, 0, 0, 2, 1}→{1, 1, 0, 2, 1}···

Note that the configuration {1, 1, 0, 2, 1}is obtained by incrementing every value in {0, 0, 2, 1, 0} by 1, where the increment operation is done modulo $n − 2 = 3$, and therefore the configuration {0, 0, 2, 1, 0} is reached again after activating each processor $n − 2 = 3$ times when the processors are repeatedly activated in the order specified above. Thus, there exists an infinite execution in which more than one processor can change a state in every configuration. This execution has no suffix in $ME$, and therefore the algorithm is not self stabilizing with relation to $ME$.

注意，配置 {1, 1, 0, 2, 1} 是通过将 {0, 0, 2, 1, 0} 中的每个值增加 1 获得的，其中增加操作是以模 $n − 2 = 3$ 进行的，因此在按上述顺序重复激活每个处理器 $n − 2 = 3$ 次后，配置 {0, 0, 2, 1, 0} 再次达到。因此，存在一个无限执行，其中在每个配置中有多个处理器可以改变状态。这个执行在 $ME$ 中没有后缀，因此该算法相对于 $ME$ 不是自稳定的。

It seems at first glance that the powerful central daemon scheduler guarantees some sort of mutual exclusion by activating one processor at a time. One can ask whether an algorithm in which every processor $P_i$ executes the critical section (whenever the central daemon activates $P_i$) is a mutual exclusion algorithm.

听起来强大的中央守护进程调度器通过每次激活一个处理器来保证某种互斥。有人可能会问，一个算法中，每当中央守护进程激活处理器 $P_i$ 时，该处理器 $P_i$ 执行临界区，这是否是一个互斥算法。

To answer the above question, let us consider a multitasking single-processor computer in which, at any given time, exactly one process is executed by the single processor. In such settings, one of the processes $P_i$ may enter the critical section (e.g., may start using a resource such as the printer). $P_i$ may be suspended while it is in the critical section by the operating system, due to task switching. We would not want any other process to enter the critical section (and, say, start printing) as long as $P_i$ is in the critical section. Clearly, Dijkstra’s algorithm can be used to coordinate the activity of the processes in such a system in the following way: the single process $P_i$ that can change a state is the one that may access the critical section. Only when process $P_i$ is finished with the critical section does it change the value of $x_i$.

要回答上述问题，让我们考虑一个多任务单处理器计算机，在任何给定时间内，单处理器只执行一个进程。在这种情况下，某个进程 $P_i$ 可能会进入临界区（例如，开始使用资源如打印机）。$P_i$ 可能会因为操作系统的任务切换而在临界区内被挂起。当 $P_i$ 在临界区时，我们不希望任何其他进程进入临界区（例如，开始打印）。显然，Dijkstra 的算法可以用来协调这样一个系统中的进程活动：可以改变状态的单个进程 $P_i$ 是唯一可以访问临界区的进程。只有当进程 $P_i$ 完成临界区的操作后，它才会改变 $x_i$ 的值。

On the negative side, we demonstrate that Dijkstra’s algorithm needs more states to work if steps consists of only one communication operation, read or write. (The term *read/write* *atomicity* describes the operations in such a system.) To do this we introduce an internal variable $l_{xi}$ for every processor $P_i$ in which is stored the last value read by $P_i$ from the $x$ variable of the left neighbor of $P_i$. Note that the existence of such a variable is enforced by the new atomicity, since a write operation is not executed in the same atomic step as a read operation and the value written is a function of the last value read. Now a possible configuration is a vector  $c = \{(l_{x1}, x1), (l_{x2}, x2),··· , (l_{xn}, xn)\}$. A read operation of $P_i$, $1 < i ≤ n$, copies the value of $x_{i−1}$ into $l_{xi}$; a read operation of $P_1$ copies the value of $x_n$ into $l_{x1}$. A write operation of $P_i$, $1 < i ≤ n$, copies the value of $l_{xi}$ into $x_i$; a write operation of $P_1$ assigns $(l_{x1} + 1) \mod K$ to $x_1$, where, from our previous discussion, $K > (n − 2)$. If we reexamine the operation of every processor in the read/write atomicity model, we discover that the n−processor ring in this model is identical to a ring of $2n$ processors in a system with a central daemon. A read operation is essentially a copy of the value of the left neighbor. A write operation by every processor $P_i$, $i \neq 1$, is also a copy operation from $l_{xi}$ to $x_i$. $x_1$ is the only variable that is incremented modulo $K$ during a write operation. Thus, we can apply our previous proofs and discussion to conclude that $K$ must be greater than $2n − 2$.

在负面方面，我们证明了如果步骤仅由一个通信操作（读取或写入）组成，Dijkstra 算法需要更多的状态才能工作。（术语“读/写原子性”描述了这种系统中的操作。）为此，我们为每个处理器 $P_i$ 引入一个内部变量 $l_{xi}$，其中存储了 $P_i$ 从其左邻居的 $x$ 变量中读取的最后一个值。注意，这种变量的存在是由新的原子性强制要求的，因为写操作并不是在与读操作相同的原子步骤中执行的，并且写入的值是最后读取值的函数。现在，可能的配置是一个向量 $c = \{(l_{x_1}, x_1), (l_{x_2}, x_2),··· , (l_{x_n}, x_n)\}$。$P_i$ 的读操作，$1 < i ≤ n$，将 $x_{i−1}$ 的值复制到 $l_{x_i}$；$P_1$ 的读操作将 $x_n$ 的值复制到 $l_{x_1}$。$P_i$ 的写操作，$1 < i ≤ n$，将 $l_{x_i}$ 的值复制到 $x_i$；$P_1$ 的写操作将 $(l_{x_1} + 1) \mod K$ 赋给 $x_1$，根据我们之前的讨论，$K > (n − 2)$。如果我们重新检查在读/写原子性模型中每个处理器的操作，我们会发现该模型中的 $n$ 处理器环与带有中央守护进程的系统中的 $2n$ 处理器环是相同的。读操作本质上是左邻居值的复制。每个处理器 $P_i$（$i \neq 1$）的写操作也是从 $l_{x_i}$ 到 $x_i$ 的复制操作。$x_1$ 是唯一在写操作期间以模 $K$ 增加的变量。因此，我们可以应用之前的证明和讨论，得出 $K$ 必须大于 $2n − 2$。

In figure 2.3 circles represent processors and rectangles represent communication registers. The left portion of figure 2.3 represents a system for which read/write atomicity is assumed. The arrows in the left portion denote the ability of $P_i$ to write (the value of $l_{xi}$, if $i \neq 1$) in $x_i$ and read the value of $x_{i−1}$  (into $l_{xi}$). The right portion of figure 2.3 represents a system for which a central daemon is assumed. The arrows in this portion denote the ability of $P_i$ to use the state of its left neighbor together with its own state for its transition function. Note that there is no need to store a value read from a (register of a) processor in a local variable. Whenever the central daemon schedules a processor to execute a step, the state of the left neighbor (the value read from the left neighbor) is used by $P_i$ in the very same (aggregate) step to compute its next state.
在图 2.3 中，圆圈表示处理器，矩形表示通信寄存器。图 2.3 的左部分表示假定具有读/写原子性的一种系统。左部分中的箭头表示 $P_i$ 能够在 $x_i$ 中写入值（$l_{x_i}$ 的值，如果 $i \neq 1$）并读取 $x_{i−1}$ 的值（到 $l_{xi}$ 中）。图 2.3 的右部分表示假定具有中心守护进程的一种系统。此部分中的箭头表示 $P_i$ 能够使用其左邻居的状态及其自身的状态来进行状态转换函数。请注意，不需要将从（一个处理器的寄存器）读取的值存储在局部变量中。每当中心守护进程安排处理器执行一个步骤时，左邻居的状态（从左邻居读取的值）在同一个（聚合）步骤中由 $P_i$ 使用来计算其下一个状态。

![figure_2.3](images/figure_2.3.png)