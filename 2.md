# 2 Definitions, Techniques, and Paradigms

<!-- TOC -->

- [2 Definitions, Techniques, and Paradigms](#2-definitions-techniques-and-paradigms)
  - [2.1 Definitions of the Computational Model](#21-definitions-of-the-computational-model)
  - [2.2 Self-Stabilization Requirements](#22-self-stabilization-requirements)
  - [2.3 Complexity Measures](#23-complexity-measures)
  - [2.4 Randomized Self-Stabilization](#24-randomized-self-stabilization)
  - [2.5 Example: Spanning-Tree Construction](#25-example-spanning-tree-construction)
  - [2.6 Example: Mutual Exclusion](#26-example-mutual-exclusion)
  - [2.7 Fair Composition of Self-Stabilizing Algorithms](#27-fair-composition-of-self-stabilizing-algorithms)

<!-- /TOC -->
This chapter is devoted to formalizing the distributed system, the basic assumptions, the requirements, and the complexity measures. The formal definitions are then used in the description of basic techniques and paradigms in the design of self-stabilizing algorithms and in proving their correctness.

本章致力于形式化分布式系统、基本假设、需求和复杂性度量。然后，这些形式化定义将用于描述自稳定算法设计中的基本技术和范式，并证明其正确性。

## 2.1 Definitions of the Computational Model

The term *distributed system* is used to describe communication networks, multiprocessor computers, and a multitasking single computer. All the above variants of distributed systems have similar fundamental coordination requirements among the communicating entities, whether they are computers, processors, or processes. Thus **an abstract model** that **ignores the specific setting** and captures the important characteristics of a distributed system is usually employed.

*分布式系统* 一词用于描述通信网络、多处理器计算机和多任务单计算机。上述所有分布式系统的变体在通信实体（无论是计算机、处理器还是进程）之间都有类似的基本协调需求。因此，通常采用一种**忽略具体设置**并捕捉分布式系统重要特征的**抽象模型**。

Each computer runs a program composed of executable statements. Each execution of a statement changes the content of the computer’s local memory, including the program counter. In other words, the computer changes state with each statement execution. An abstract way to model a computer that executes a program is to use the state machine model. **A distributed system is modeled by a set of $n$ state machines called processors that communicate with each other. We usually denote the $i$ th processor in the system by $P_i$ . Each processor can communicate with other processors, called its neighbors.** It is convenient to represent a distributed system by a communication graph in which each processor is represented by a node and every two neighboring processors are connected by a link of the communication graph.

每台计算机运行由可执行语句组成的程序。每次执行语句都会改变计算机本地内存的内容，包括程序计数器。换句话说，计算机在每次语句执行时都会改变状态。抽象地说，执行程序的计算机可以用状态机模型来表示。**分布式系统由一组称为处理器的 $n$ 个状态机组成，它们相互通信。我们通常用 $P_i$ 表示系统中的第 $i$ 个处理器。每个处理器可以与其他处理器（称为其邻居）通信。**用通信图表示分布式系统是很方便的，其中每个处理器用一个节点表示，每两个相邻的处理器通过通信图的一个链接连接。

**The communication between neighboring processors can be carried out by message passing or shared memory. Communication by writing in, and reading from, the shared memory usually fits systems with processors that are geographically close together, such as multiprocessor computers or processes executed by a multitasking single-processor computer. A message-passing distributed model fits both processors that are located close to each other and wide-area distributed systems, such as communication networks.**

**相邻处理器之间的通信可以通过消息传递或共享内存进行。通过写入和读取共享内存进行通信通常适用于地理位置接近的处理器系统，例如多处理器计算机或由多任务单处理器计算机执行的进程。消息传递分布式模型适用于彼此靠近的处理器和广域分布式系统，例如通信网络。**

In the message-passing model, neighbors communicate by sending and receiving messages. In asynchronous distributed systems, the speed of processors and message transmission can vary. First-in first-out (FIFO) queues are used to model asynchronous delivery of messages. A communication link is either unidirectional or bidirectional. **A unidirectional communication link from processor $P_i$ to processor $P_j$ transfers messages from $P_i$ to $P_j$ . The abstraction used for such a unidirectional link is a first-in first-out (FIFO) queue $q_{i,j}$ , that contains all messages sent by a processor $P_i$ to its neighbor $P_j$ that have not yet been received.** Whenever $P_i$ sends a message $m$ to $P_j$, the message is enqueued (added to the tail of the queue). $P_j$ may receive the message $m$ that is at the head of the queue; in such a case, the message $m$ is dequeued (removed from the front of the queue). The bidirectional communication link between processors $P_i$ and $P_j$ is modeled by two FIFO queues, one from $P_i$ to $P_j$ and the other from $P_j$ to $P_i$.

在消息传递模型中，相邻节点通过发送和接收消息进行通信。在异步分布式系统中，处理器的速度和消息传输的速度可以有所不同。先进先出（FIFO）队列用于模拟消息的异步传递。通信链路可以是单向的或双向的。**从处理器 $P_i$ 到处理器 $P_j$ 的单向通信链路将消息从 $P_i$ 传输到 $P_j$。用于这种单向链路的抽象是先进先出（FIFO）队列 $q_{i,j}$，它包含了所有由处理器 $P_i$ 发送给其邻居 $P_j$ 但尚未被接收的消息。**每当 $P_i$ 向 $P_j$ 发送消息 $m$ 时，该消息会被入队（添加到队列的尾部）。$P_j$ 可以接收位于队列头部的消息 $m$；在这种情况下，消息 $m$ 会被出队（从队列的前端移除）。处理器 $P_i$ 和 $P_j$ 之间的双向通信链路由两个 FIFO 队列建模，一个从 $P_i$ 到 $P_j$，另一个从 $P_j$ 到 $P_i$。

It is very convenient to identify the state of a computer or a distributed system at a given time, so that no additional information about the past of the computation is needed in order to predict the future behavior (state transitions) of the computer or the distributed system. **A full description of a message passing distributed system at a particular time consists of the state of every processor and the content of every queue (messages pending in the communication links). The term *system configuration* (or *configuration*) is used for such a description.** A configuration is denoted by $c = (s_1, s_2, ..., s_n, q_{1,2}, q_{1,3}, ..., q_{i,j}, ..., q_{n-1,n})$, where $s_i$, $1 ≤ i ≤ n$, is the state of $P_i$ and $q_{i,j}$, $i ≠ j$, is the queue of messages sent by $P_i$ to $P_j$ but not yet received.

在某个特定时间识别计算机或分布式系统的状态非常方便，这样就不需要额外的信息来预测计算机或分布式系统的未来行为（状态转换）。**在特定时间对消息传递分布式系统的完整描述包括每个处理器的状态和每个队列的内容（通信链路中未处理的消息）。这种描述称为系统配置（或配置）。**配置表示为 $c = (s_1, s_2, ..., s_n, q_{1,2}, q_{1,3}, ..., q_{i,j}, ..., q_{n-1,n})$，其中 $s_i$，$1 ≤ i ≤ n$，是 $P_i$ 的状态，$q_{i,j}$，$i ≠ j$，是 $P_i$ 发送给 $P_j$ 但尚未接收的消息队列。

**In the shared memory model, processors communicate by the use of shared communication registers (hereafter *registers*). Processors may write in a set of registers and may read from a possibly different set of registers. The configuration of the system consists of the state of all processors and the contents of the registers.** A configuration with $n$ processors and $m$ communication registers is denoted by $c = (s_1, s_2, ..., s_n; r_1, r_2, ..., r_m)$, where $s_i$, $1 ≤ i ≤ n$, is the state of $P_i$ and for $1 ≤ j ≤ m$, $r_j$ is the contents of a communication register.

**在共享内存模型中，处理器通过使用共享通信寄存器（以下简称 *寄存器*）进行通信。处理器可以写入一组寄存器，并且可以从可能不同的一组寄存器中读取。系统的配置包括所有处理器的状态和寄存器的内容。**具有 $n$ 个处理器和 $m$ 个通信寄存器的配置表示为 $c = (s_1, s_2, ..., s_n; r_1, r_2, ..., r_m)$，其中 $s_i$，$1 ≤ i ≤ n$，是 $P_i$ 的状态，对于 $1 ≤ j ≤ m$，$r_j$ 是通信寄存器的内容。

The future state transitions of a stand-alone computer that executes a (non-interactive) program can be deterministically predicted from its current state. Note that, for a stand-alone computer, the speed of the state transitions may not be fixed (in a multitasking computer environment, the period of time for which each task is executed may change over time); nevertheless, when the tasks are totally independent, we can predict the state of each task following the $i$ th state transition of this task. The situation in distributed systems is different. Nondeterminism due to different speeds of processors and of message delivery can result in totally different state transitions of processors from identical initial states. For example, a processor waiting to receive messages from one of each of its neighbors may act differently if a message from neighbor $P_i$ arrives before a message from $P_j$ , or vice versa. **In other words, scheduling of events in a distributed system influences the transitions made by the processors. The situation is even more complicated, since processors execute program statements in parallel at different rates.**

执行（非交互式）程序的独立计算机的未来状态转换可以从其当前状态确定性地预测。注意，对于独立计算机，状态转换的速度可能不是固定的（在多任务计算机环境中，每个任务执行的时间段可能会随时间变化）；尽管如此，当任务完全独立时，我们可以在该任务的第 $i$ 次状态转换后预测每个任务的状态。分布式系统中的情况则不同。由于处理器和消息传递速度的不同导致的不确定性可能会导致处理器从相同的初始状态进行完全不同的状态转换。例如，一个处理器等待从每个邻居接收消息时，如果来自邻居 $P_i$ 的消息先于来自 $P_j$ 的消息到达，或者反之亦然，它可能会有不同的行为。换句话说，**分布式系统中事件的调度会影响处理器的转换。情况更加复杂，因为处理器以不同的速率并行执行程序语句。**

**The interleaving model is used to reason about the behavior of the distributed system.** In this model it is assumed that, at each given time, only a single processor executes a *computation step* (also called an *atomic step*). **Each computation step consists of internal computation and a single communication operation: a send or receive in message passing systems and a write or read in shared memory systems.** Note that a computation step may consist of local computations (e.g., subtraction of the values of two local registers of the processors) in addition to the communication operation. Without loss of generality, the time at which all the local operations between two communication operations of a processor occur is assumed to be immediately before the second communication operation. Thus, **it is possible to assume that every state transition of a process is due to communication-step execution** (including all local computations that follow the previous step and precede the communication operation of the computation step).

**交错模型用于推理分布式系统的行为。**在该模型中，假设在每个给定时间，只有一个处理器执行一个 *计算步骤*（也称为 *原子步骤*）。**每个计算步骤包括内部计算和一个通信操作：在消息传递系统中是发送或接收，在共享内存系统中是写入或读取。**注意，计算步骤除了通信操作外，还可能包括本地计算（例如，处理器的两个本地寄存器值的减法）。在不失一般性的情况下，假设处理器的两个通信操作之间的所有本地操作发生的时间是紧接在第二个通信操作之前。因此，**可以假设进程的每个状态转换都是由于通信步骤的执行**（包括所有在前一步之后和计算步骤的通信操作之前的本地计算）。

Note that **a distributed system allows the processors to execute steps concurrently**; however, **when processors execute steps concurrently we assume that there is no influence of one step on the other**. This is clearly true for send and receive operations that are executed simultaneously, because a message sent cannot be received by a receive operation that is executed at the same time. As for shared memory, it is assumed that the communication register architecture guarantees serialization: the read and write operations can be ordered in a total order such that the result of a read operation from some register is the value that was written last before this read (according to the total order) in that register.

请注意，**分布式系统允许处理器并发执行步骤**；然而，**当处理器并发执行步骤时，我们假设一个步骤不会对另一个步骤产生影响。**这对于同时执行的发送和接收操作显然是正确的，因为发送的消息不能被同时执行的接收操作接收。对于共享内存，假设通信寄存器架构保证了序列化：读和写操作可以按总顺序排列，使得从某个寄存器进行的读操作的结果是该寄存器中在此读操作之前最后写入的值（根据总顺序）。

In what follows, we use the term *step* for a computation step and we **denote a step (together with the identity of the processor that executes it) by $a$.** Let $c_1$ and $c_2$ be two configurations of the system, **where $c_2$ is reached from $c_1$ by a single step $a$ of a processor; we denote this fact by $c_1 \xrightarrow{a} c_2$.** The step $a$ is *applicable* to a configuration $c$ if (and only if) there exists a configuration $c’$ such that $c \xrightarrow{a} c’$.

An execution $E = (c_1, a_1, c_2, a_2,···)$ (in the interleaving model) is **an alternating sequence of configurations and steps** such that $c_{i−1} \xrightarrow{a_{i−1}} c_i$ ($i > 1$); in other words, the configuration $c_i$ ($i > 1$) is obtained from $c_{i−1}$ by the execution of step $a_{i−1}$. For instance, if in step ai the processor $P_j$ writes the value $x$ to a register $r_k$ , then the only components that do not have identical values in $c_i$ and $c_{i+1}$ are the state of $P_j$ and the value of $r_k$ , which were changed according to $a_i$. A *fair* execution is **an execution in which every step that is applicable infinitely often is executed infinitely often**. In particular, if (infinitely often) a processor has a step to execute then the processor executes this step (infinitely often).

在下文中，我们使用术语 *步骤* 来表示计算步骤，并**用 $a$ 表示一个步骤**（以及执行该步骤的处理器的身份）。设 $c_1$ 和 $c_2$ 是系统的两个配置，**其中 $c_2$ 通过处理器的单个步骤 $a$ 从 $c_1$ 达到；我们用 $c_1 \xrightarrow{a} c_2$ 表示这一事实**。当且仅当存在一个配置 $c'$ 使得 $c \xrightarrow{a} c'$ 时，步骤 $a$ 才 *适用* 于配置 $c$。

一个执行 $E = (c_1, a_1, c_2, a_2,···)$（在交错模型中）是**配置和步骤的交替序列**，使得 $c_{i−1} \xrightarrow{a_{i−1}} c_i \, (i>1)$；换句话说，配置 $c_i \, (i>1)$ 是通过执行步骤 $a_{i−1}$ 从 $c_{i−1}$ 获得的。例如，如果在步骤 $a_i$ 中处理器 $P_j$ 将值 $x$ 写入寄存器 $r_k$，那么在 $c_i$ 和 $c_{i+1}$ 中唯一不具有相同值的组件是 $P_j$ 的状态和 $r_k$ 的值，它们根据 $a_i$ 发生了变化。*公平* 执行是指**每个无限次适用的步骤都被无限次执行的执行**。特别地，如果（无限次）一个处理器有一个步骤要执行，那么处理器就会执行这个步骤（无限次）。

In a **message-passing system**, it is possible that a message will be lost during the execution of the algorithm; the reason is unreliable communication media that may lose or corrupt messages in transit. Error-detection codes are used to identify and discard corrupted messages, and these messages can be considered lost messages. To model such systems, we extend the definition of a step to include *environment steps* of type $loss_{i,j}(m)$.

The environment step $loss_{i,j}(m)$ is applicable to a configuration $c_k$ in which the queue $q_{i,j}$ contains the message $m$. The application of $loss_{i,j}(m)$ to $c_k$ results in a configuration $c_{k+1}$ in which $m$ is **removed** from $q_{i,j}$ , and $c_k$ and $c_{k+1}$ are identical in the rest of their components.

Unlike steps executed by processors, we do not require that, in every infinite fair execution, the environment steps that are applicable infinitely often will be executed infinitely often. **We do require that, in a fair execution in which a message is sent infinitely often, the message must be received infinitely often.** To satisfy fairness the receive step must be executed infinitely often, while the loss step should not be executed infinitely often.

在**消息传递系统**中，算法执行过程中可能会丢失消息；原因是通信介质不可靠，可能会在传输过程中丢失或损坏消息。错误检测码用于识别和丢弃损坏的消息，这些消息可以被视为丢失的消息。为了对这种系统建模，我们扩展了步骤的定义，包括类型为 $loss_{i,j}(m)$ 的环境步骤。

环境步骤 $loss_{i,j}(m)$ 适用于队列 $q_{i,j}$ 包含消息 $m$ 的配置 $c_k$*将 $loss_{i,j}(m)$ 应用于 $c_k$ 会导致配置 $c_{k+1}$，其中 $m$ 从 $q_{i,j}$ 中**移除**，$c_k$ 和 $c_{k+1}$ 在其余组件中是相同的。

与处理器执行的步骤不同，我们不要求在每个无限公平执行中，无限次适用的环境步骤将被无限次执行。**我们确实要求，在一个消息无限次发送的公平执行中，该消息必须被无限次接收。**为了满足公平性，接收步骤必须被无限次执行，而丢失步骤不应被无限次执行。

Up to this stage, we have presented the class of distributed systems called *asynchronous* distributed systems. The experience of distributed algorithm designers is that algorithms designed for asynchronous systems perform well in communication networks and multiprocessor systems. **Yet there is a class of distributed algorithms designed for *synchronous* distributed systems in which a *global clock pulse* (or simply a *pulse*) triggers a simultaneous step of every processor in the system.** This class of synchronous algorithms fits multiprocessor systems in which the processors are located close to each other and can therefore be efficiently connected to a common clock pulse. Next we describe the assumptions concerning the steps of the processors in synchronous message-passing and shared-memory systems.

到目前为止，我们已经介绍了称为 *异步* 分布式系统的分布式系统类别。分布式算法设计者的经验是，为异步系统设计的算法在通信网络和多处理器系统中表现良好。然而，还有一类**为 *同步* 分布式系统设计的分布式算法**，其中 ***全局时钟脉冲*（或简称 *脉冲*）触发系统中每个处理器的同步步骤**。这类同步算法适用于处理器彼此靠近并且可以高效连接到公共时钟脉冲的多处理器系统。接下来，我们描述同步消息传递和共享内存系统中处理器步骤的假设。

The following actions are performed between each successive pulses of a synchronous message-passing system: the pulse triggers message send operations of every processor to every one of its neighbors, then every message is received by its destination. In the shared memory system, a pulse triggers each processor to read all the registers of its neighbors. Once every processor has finished reading, the processors can write into their registers. Thus, since all the processors execute a step simultaneously, **the execution of a synchronous system $E = (c_1, c_2,···)$ is totally defined by $c_1$, the first configuration in $E$.**

在同步消息传递系统的每个连续脉冲之间执行以下操作：脉冲触发每个处理器向其所有邻居发送消息操作，然后每条消息被其目的地接收。在共享内存系统中，脉冲触发每个处理器读取其所有邻居的寄存器。一旦每个处理器完成读取，处理器就可以写入它们的寄存器。因此，由于所有处理器同时执行一个步骤，**同步系统的执行 $E = (c_1, c_2,···)$ 完全由 $c_1$（即 $E$ 中的第一个配置）定义。**

## 2.2 Self-Stabilization Requirements

**A self-stabilizing system can be started in any arbitrary configuration and will eventually exhibit a desired “legal” behavior.**

**We define the desired legal behavior by a set of legal executions denoted $LE$.** A set of legal executions is defined for a particular system and a particular task. **Every system execution of a self-stabilizing system should have a suffix that appears in $LE$.** For instance, when the task is *mutual exclusion*, the task is defined by the set of legal executions in which, in every configuration, there is at most one processor in the critical section, and in which every processor is in the critical section in an infinite number of configurations of the execution.

**A configuration $c$ is *safe* with regard to a task $LE$ and an algorithm if every fair execution of the algorithm that starts from $c$ belongs to $LE$.**

**An algorithm is *self-stabilizing* for a task $LE$ if every fair execution of the algorithm reaches a safe configuration with relation to $LE$.**

**自稳定系统可以从任何任意配置开始，并最终表现出期望的“合法”行为。**

**我们通过一组合法执行（记为 $LE$）来定义期望的合法行为。**对于特定系统和特定任务，定义了一组合法执行。**自稳定系统的每个系统执行都应该有一个后缀出现在 $LE$ 中。**例如，当任务是 *互斥* 时，该任务由一组合法执行定义，在每个配置中，最多只有一个处理器在临界区，并且每个处理器在执行的无限多个配置中都在临界区。

**对于任务 $LE$ 和算法，如果从配置 $c$ 开始的算法的每个公平执行都属于 $LE$，则配置 $c$ 对该任务是安全的。**

**如果算法的每个公平执行都达到与任务 $LE$ 相关的安全配置，则该算法对任务 $LE$ 是 *自稳定* 的。**

## 2.3 Complexity Measures

The complexity measures used to evaluate an algorithm include time complexity and space (memory) complexity. At first glance, the attempt to define the time complexity of asynchronous systems may seem to contradict the asynchronous nature of the system. By the definition of asynchronous systems, there is no bound on the rate/speed of step-executions/message-arrivals. However, in order to evaluate and compare different asynchronous algorithms, it is convenient to use the number of *asynchronous rounds* to measure the time complexity of a particular execution. The first *asynchronous round* (or *round*) in an execution $E$ is the shortest prefix $E'$ of E **such that each processor executes at least one step in $E’$**. Let $E''$ be the suffix of $E$ that follows $E’$, $E = E'E''$. The second round of $E$ is the first round of $E''$, and so on. The number of rounds in the execution of an algorithm is used to measure the time complexity of the algorithm.

用于评估算法的复杂度度量包括时间复杂度和空间（内存）复杂度。乍一看，试图定义异步系统的时间复杂度似乎与系统的异步性质相矛盾。根据异步系统的定义，步骤执行/消息到达的速率/速度没有上限。然而，为了评估和比较不同的异步算法，使用 *异步轮* 数来衡量特定执行的时间复杂度是很方便的。执行 $E$ 中的第一个 *异步轮*（或 *轮*）是 $E$ 的最短前缀 $E'$，使得**每个处理器在 $E'$ 中至少执行一步**。设 $E''$ 为 $E$ 的后缀，紧随 $E'$ 之后，$E = E'E''$。$E$ 的第二轮是 $E''$ 的第一轮，依此类推。算法执行中的轮数用于衡量算法的时间复杂度。

Intuitively, **the definition of an asynchronous round nullifies the speed differences of the processors by stretching the round to be long enough to include a step (including a communication operation) of the slowest processor in this execution segment. Thus, information can be transferred through the slowest processor even if that processor resides in a node that can separate the communication graph.** Moreover, if the speeds of the processors are identical and the speeds of message transmission are also identical, every asynchronous round elapses in the same constant time interval.

直观地说，**异步轮的定义通过将轮延长到足够长，以包括此执行段中最慢处理器的一步（包括通信操作），从而消除了处理器速度的差异。因此，即使该处理器位于可以分隔通信图的节点中，信息也可以通过最慢的处理器传输。**此外，如果处理器的速度相同且消息传输的速度也相同，则每个异步轮在相同的恒定时间间隔内经过。

**A self-stabilizing algorithm never terminates, and processors must repeatedly communicate with their neighbors.** In the shared-memory model, processors must repeatedly read the registers of their neighbors and in the message passing model, processors must continue to send and receive messages forever.

The following argument is used to explain why termination cannot be achieved: assume that every processor $P_i$ has a state $s_i$ in which $P_i$ is **terminated**. By the self-stabilizing property of the algorithm, the system must reach a safe configuration from any initial configuration. When the system is started in a configuration $c$ in which every processor $P_i$ is in state $s_i$, no processor executes any step, and thus $c$ must be a safe configuration. Therefore the task of the algorithm is achieved when every processor $P_i$ has only one state, namely the state $s_i$. Obviously, such tasks do not require any communication between the processors and the “algorithm” that is used is not a distributed algorithm.

**自稳定算法永不终止，处理器必须反复与其邻居通信。**在共享内存模型中，处理器必须反复读取其邻居的寄存器；在消息传递模型中，处理器必须不断发送和接收消息。

以下论点用于解释为什么无法实现终止：假设每个处理器 $P_i$ 有一个状态 $s_i$，其中 $P_i$ **终止**。根据算法的自稳定性，系统必须从任何初始配置达到安全配置。当系统在配置 $c$ 中启动时，其中每个处理器 $P_i$ 都处于状态 $s_i$，没有处理器执行任何步骤，因此 $c$ 必须是一个安全配置。因此，当每个处理器 $P_i$ 只有一个状态，即状态 $s_i$ 时，算法的任务就完成了。显然，这样的任务不需要处理器之间的任何通信，并且所使用的“算法”不是分布式算法。

The non-termination property can be easily identified in the code of a self-stabilizing algorithm: this code is usually a do forever loop that contains communication operations with the neighbors. For example, **in the shared memory case, the code of the algorithm for a processor $P_i$ usually starts with read operations of the communication registers of $P_i$ and then local computations that are followed by write operations in the communication registers of  $P_i$. The number of steps required to execute a single iteration of such a do forever loop is $O(\triangle)$, where $\triangle$ is an upper bound on the degree (number of neighbors) of  $P_i$**. In some of the proofs, it is very convenient to consider the configuration that follows at least one complete execution of an iteration of the do forever loop by every processor. **Note that a processor can be started in (a state in which it is in) the middle of executing an iteration of the do forever loop. However, if $x$ is the number of steps required to complete an iteration of the do forever loop, then fewer than $2x$ steps are required to complete an iteration of the loop (from the beginning of the loop to its end) when $P_i$ is started in an arbitrary state.**

自稳定算法的非终止特性可以很容易地在代码中识别出来：这段代码通常是一个包含与邻居通信操作的永久循环。例如，**在共享内存情况下，处理器 $P_i$ 的算法代码通常以读取 $P_i$ 的通信寄存器操作开始，然后是本地计算，接着是写入 $P_i$ 的通信寄存器操作。执行这样一个永久循环的单次迭代所需的步骤数是 $O(\triangle)$，其中 $\triangle$ 是 $P_i$ 的度（邻居数量）的上限。**在一些证明中，考虑每个处理器至少完整执行一次永久循环迭代后的配置是非常方便的。注意，**处理器可以在执行永久循环迭代的中间状态启动。然而，如果完成永久循环迭代所需的步骤数为 $x$，那么当 $P_i$ 从任意状态启动时，完成循环迭代（从循环的开始到结束）所需的步骤数少于 $2x$。**

For the sake of readability, we extend the definition of an asynchronous round to an asynchronous *cycle* when convenient. **The first *asynchronous cycle* (or *cycle*) in an execution $E$ is the shortest prefix $E'$ of $E$ such that each processor executes at least one complete iteration of its do forever loop in $E'$. Let $E''$ be the suffix of $E$ that follows $E'$, $E = E'E''$. The second cycle of $E$ is the first cycle of $E'$, and so on.**

为了便于阅读，我们在方便时将异步轮的定义扩展为异步 *周期*。**执行 $E$ 中的第一个 *异步周期*（或 *周期*）是 $E$ 的最短前缀 $E'$，使得每个处理器在 $E'$ 中至少执行一次其永久循环的完整迭代。设 $E''$ 为 $E$ 的后缀，紧随 $E'$ 之后，$E = E'E''$。$E$ 的第二个周期是 $E''$ 的第一个周期，依此类推。**

Note that if the do forever iteration consists of reading the communication registers of the neighbors, local computations, and writing to the communication registers, then each cycle spans $O(\triangle)$ rounds.

请注意，如果永久循环的迭代包括读取邻居的通信寄存器、本地计算和写入通信寄存器，那么每个周期跨越 $O(\triangle)$ 轮。

The time complexity of a synchronous algorithm is the number of pulses in the execution (which corresponds to the number of rounds).

同步算法的时间复杂度是执行中的脉冲数（对应于轮数）。

The space complexity of an algorithm is the total number of (local and shared) memory bits used to implement the algorithm.

算法的空间复杂度是用于实现算法的（本地和共享）内存位的总数。

## 2.4 Randomized Self-Stabilization

随机自稳定

So far we have not concerned ourselves with randomized algorithms — i.e., those that use coin-toss or random-function results to determine their actions. An important subject in self-stabilization research is the study of randomized self-stabilizing algorithms. Breaking symmetry is sometimes impossible without using randomization.

In order to define the requirements for randomized self-stabilizing algorithms, we use the following assumptions and definitions. Processor activity is managed by a scheduler. The scheduler is merely an abstraction of the assumption made for the interleaving model, that at most one step is executed in every given time. In any given configuration, the scheduler activates a single processor, which executes a single step. To ensure correctness of the algorithms, we regard the scheduler as an adversary. The scheduler is assumed to have unlimited resources and chooses the next activated processor *on line*, using all the information about the execution so far. A scheduler $S$ is *fair* if, for any configuration $c$ with probability 1, an execution starting from $c$ in which processors are activated by $S$ is fair.

Finally, an algorithm is *randomized self-stabilizing* for a task $LE$ if, starting with any system configuration and considering any fair scheduler, the algorithm reaches a safe configuration within an expected number of rounds that is bounded by some constant $k$ ($k$ may depend on $n$, the number of processors in the system).

Randomized algorithms are often used to break symmetry in a system of totally identical processors in which processors do not have unique identifiers. The terms *uniform* or *anonymous system* are used for such systems.

到目前为止，我们还没有涉及随机算法——即使用抛硬币或随机函数结果来决定其动作的算法。自稳定研究中的一个重要课题是随机自稳定算法的研究。在某些情况下，不使用随机化是无法打破对称性的。

为了定义随机自稳定算法的要求，我们使用以下假设和定义。处理器活动由调度器管理。调度器只是交错模型假设的抽象，即在任何给定时间内最多执行一个步骤。在任何给定配置中，调度器激活一个处理器，该处理器执行一个步骤。为了确保算法的正确性，我们将调度器视为对手。假设调度器拥有无限资源，并 *在线* 选择下一个激活的处理器，使用到目前为止的所有执行信息。如果对于任何配置 $c$，以概率 1 从 $c$ 开始的执行中，调度器 $S$ 激活处理器是公平的，则称调度器 $S$ 是 *公平* 的。

最后，如果对于任务 $LE$，从任何系统配置开始并考虑任何公平调度器，算法在期望的轮数内达到安全配置，并且该期望轮数由某个常数 $k$（$k$ 可能依赖于系统中的处理器数量 $n$）界定，则该算法是 *随机自稳定* 的。

随机算法通常用于在完全相同的处理器系统中打破对称性，这些处理器没有唯一标识符。对于这样的系统，使用 *统一* 或 *匿名系统* 术语。

## 2.5 Example: Spanning-Tree Construction

例子：生成树构造

To demonstrate the use of our definition and requirements, we present a simple self-stabilizing algorithm for marking a breadth-first search (*BFS*) spanning tree over the communication graph of the distributed system $G(V, E)$. Each node $v_i ∈ V$ represents the processor $P_i$, and each edge $(v_i, v_j) ∈ E$ indicates that $P_i$ and $P_j$ are neighbors; i.e., they can communicate with each other. For this example we use the shared memory model. A processor $P_i$ communicates with its neighbor $P_j$ by writing in the communication register $r_{ij}$ and reading from $r_{ji}$. A processor $P_i$ owns the register in which $P_i$ writes; i.e., for every neighboring processor $P_k$, the register $r_{ik}$ is owned by $P_i$.

为了展示我们定义和要求的使用，我们提出了一个简单的自稳定算法，用于标记分布式系统 $G(V, E)$ 的通信图上的广度优先搜索（*BFS*）生成树。每个节点 $v_i ∈ V$ 代表处理器 $P_i$，每条边 $(v_i, v_j) ∈ E$ 表示 $P_i$ 和 $P_j$ 是邻居；即它们可以相互通信。在这个例子中，我们使用共享内存模型。处理器 $P_i$ 通过在通信寄存器 $r_{ij}$ 中写入和从 $r_{ji}$ 中读取来与其邻居 $P_j$ 通信。处理器 $P_i$ 拥有 $P_i$ 写入的寄存器；即对于每个邻近的处理器 $P_k$，寄存器 $r_{ik}$ 由 $P_i$ 拥有。

The system consists of $n$ processors $P_1, P_2,··· , P_n$, where $P_2,··· , P_n$ run similar programs while $P_1$ is a special processor that runs a different program. $P_1$ is called the *root* processor of the tree. There is a single program that every non-root processor runs. The program has an input parameter that is the number of adjacent links of the processor. Thus, all two (non-root) processors with the same number of neighbors are identical — they run identical programs.

系统由 $n$ 个处理器 $P_1, P_2,··· , P_n$ 组成，其中 $P_2,··· , P_n$ 运行相似的程序，而 $P_1$ 是一个特殊的处理器，运行不同的程序。$P_1$ 被称为树的 *根* 处理器。每个非根处理器运行一个相同的程序。该程序有一个输入参数，即处理器的相邻链接数。因此，所有具有相同邻居数量的两个（非根）处理器是相同的——它们运行相同的程序。

Essentially **the algorithm is a distributed *BFS* algorithm**. Each processor is continuously trying to compute its distance from the root and to report this distance to all its neighbors by writing the distance in its registers. At the beginning of an arbitrary execution, the only processor guaranteed to compute the right distance is the root itself. Once this distance is written in all the root’s registers, the value stored in these registers will never be changed. **Once all processors at distance $x$ from the root have completed computing their distance from the root correctly and have written it in all their registers, their registers remain constant throughout execution**, and processors at distance $x + 1$ from the root are ready to compute their own distance from the root, and so forth.

本质上，该算法是一个**分布式的 *BFS* 算法**。每个处理器不断尝试计算其与根的距离，并通过将距离写入其寄存器来将此距离报告给所有邻居。在任意执行的开始，唯一保证能计算出正确距离的处理器是根处理器本身。**一旦这个距离被写入所有根处理器的寄存器，这些寄存器中存储的值将永远不会改变。一旦所有距离根为 $x$ 的处理器完成了与根的距离计算并将其写入所有寄存器，它们的寄存器在整个执行过程中将保持不变**，距离根为 $x + 1$ 的处理器将准备好计算它们与根的距离，依此类推。

The output tree is encoded by means of the registers as follows: each register $r_{ij}$, in which Pi writes and from which $P_j$ reads, contains a binary parent field denoted by $r_{ij}.parent$. If $P_j$ is the parent of $P_i$ in the *BFS* tree, then the value of $r_{ij}.parent$ is 1; otherwise the value of $r_{ij}.parent$ is 0. In addition, each register $r_{ij}$ has a $distance$ field, denoted by $r_{ij}.dis$, that holds the distance from the root to $P_i$ . The maximal value that can be stored in the $distance$ field is $N$, where $N$ is an upper bound on the number of processors in the system. An attempt to assign a value larger than $N$ to the $distance$ field results in the assignment of $N$.

输出树通过寄存器进行编码，如下所示：每个寄存器 $r_{ij}$，其中 $P_i$ 写入并且 $P_j$ 读取，包含一个二进制的父字段，表示为 $r_{ij}.parent$。如果 $P_j$ 是 $P_i$ 在 *BFS* 树中的父节点，那么 $r_{ij}.parent$ 的值为 1；否则 $r_{ij}.parent$ 的值为 0。此外，每个寄存器 $r_{ij}$ 还有一个 $distance$ 字段，表示为 $r_{ij}.dis$，它保存从根到 $P_i$ 的距离。$distance$ 字段中可以存储的最大值是 $N$，其中 $N$ 是系统中处理器数量的上限。尝试将大于 $N$ 的值赋给 $distance$ 字段将导致该字段被赋值为 $N$。

The code of the algorithm, for the root and for the other processors, appears in figure 2.1. In this code the number of the processor’s neighbors is given by the parameter $δ$.

The program for the root is very simple: it keeps “telling” all its neighbors that it is the root by repeatedly writing the values $<0, 0>$ in all of its registers. The first 0 tells each neighbor that it is not the parent of the root, the second 0 is the distance from the root to itself.

The program for a normal processor consists of a single loop. In this loop, the processor reads all the registers of its neighbors. Processor $P_i$ , which has $δ$ neighbors, keeps $δ$ internal variables corresponding to the $δ$ registers from which $P_i$ reads. The local variable corresponding to register $r_{ji}$, ${lr}_{ji}$, stores the last value of $r_{ji}$ read by $P_i$. Its two fields are denoted by ${lr}_{ji}.parent$ and ${lr}_{ji}.dis$, respectively. Once all these registers are read, $P_i$ computes a value for the variable $dist$ that represents $P_i$’s current idea of its distance from the root. The purpose of the boolean variable $FirstFound$ is to make sure that by the end of each pass of the loop each processor has a single parent. The minimum in line 7 is taken over $m$, $1 ≤ m ≤ δ$.

算法的代码，如图 2.1 所示，分别针对根处理器和其他处理器。在此代码中，处理器的邻居数量由参数 $δ$ 给出。

根处理器的程序非常简单：它通过在所有寄存器中反复写入值 $<0, 0>$ 来不断“告诉”所有邻居它是根。第一个 0 告诉每个邻居它不是根的父节点，第二个 0 是根到自身的距离。

普通处理器的程序由一个单一的循环组成。在这个循环中，处理器读取其所有邻居的寄存器。具有 $δ$ 个邻居的处理器 $P_i$ 保留了对应于 $P_i$ 读取的 $δ$ 个寄存器的 $δ$ 个内部变量。对应于寄存器 $r_{ji}$ 的局部变量 ${lr}_{ji}$ 存储了 $P_i$ 最后读取的 $r_{ji}$ 的值。它的两个字段分别表示为 ${lr}_{ji}.parent$ 和 ${lr}_{ji}.dis$。一旦读取了所有这些寄存器，$P_i$ 就会计算一个变量 $dist$ 的值，该值表示 $P_i$ 当前认为的它与根的距离。布尔变量 $FirstFound$ 的目的是确保在每次循环结束时每个处理器都有一个单一的父节点。第 7 行的最小值取自 $m$，$1 ≤ m ≤ δ$。

![figure_2.1](images/figure_2.1.png)

In figure 2.1 we use a program to define implicitly the set of states and the transition function of a processor. The state of a processor consists of the value of the program counter and the values of the internal variables: $m$, ${lr}_{ji}$ (for every $1 ≤ j ≤ δ$), $FirstFound$, and $dist$.

A computation step of the root processor starts with local computations that update the value of m (increment the value of $m$ by one if $m ≤ δ$, or assign $m$ := 1 otherwise). The single communication operation that is executed in a computation step of the root is a write operation of $<0, 0>$ in $r_{im}$ (where the value of $m$ is defined by the preceding local computations). The computation steps end with this write operation. The next computation step starts with the local computation that immediately follows the last write operation, and so on.

Similarly, a computation step of the non-root processor terminates in one of the three communication operations ($\text{read}(r_{mi}), \text{write}(r_{im}) := <1, dis>$ or $\text{write}(r_{im}) := <0, dis>$), and the next computation starts immediately following this communication operation.

One can argue that, in the context of self-stabilization, the value of the program counter can be arbitrary in the first system configuration and not restricted to the first local computation that follows a communication operation. Thus, it is possible that, in line 10 of the code, a $dist$ value that was not computed in line 7 is used. However, following the first computation step every computation step is well structured: it starts immediately following a communication operation and ends with the next communication operation.

在图 2.1 中，我们使用一个程序隐式地定义了处理器的状态集合和转换函数。处理器的状态包括程序计数器的值和内部变量的值：$m$，${lr}_{ji}$（对于每个 $1 ≤ j ≤ δ$），$FirstFound$ 和 $dist$。

根处理器的计算步骤从更新 $m$ 的值的本地计算开始（如果 $m ≤ δ$，则将 $m$ 的值加一，否则将 $m$ 赋值为 1）。根处理器在计算步骤中执行的唯一通信操作是在 $r_{im}$ 中写入 $<0, 0>$（其中 $m$ 的值由前面的本地计算定义）。计算步骤以此写操作结束。下一计算步骤从紧接上次写操作后的本地计算开始，依此类推。

类似地，非根处理器的计算步骤在三种通信操作之一结束（$\text{read}(r_{mi})$，$\text{write}(r_{im}) := <1, dis>$ 或 $\text{write}(r_{im}) := <0, dis>$），下一计算步骤紧接着此通信操作开始。

可以认为，在自稳定的上下文中，程序计数器的值在第一个系统配置中可以是任意的，而不局限于通信操作后的第一个本地计算。因此，在代码的第 10 行中，可能会使用第 7 行中未计算的 $dist$ 值。然而，在第一次计算步骤之后，每个计算步骤都是结构良好的：它从通信操作后立即开始，并以下一次通信操作结束。

The value of each communication register is a combination of a binary value (for the $parent$ field) and an integer (no larger than $N$ for the $dis$ field). A configuration of the system is a vector of the processor states and a vector of communication register values.

每个通信寄存器的值是二进制值（用于 $parent$ 字段）和整数（用于 $dis$ 字段，且不大于 $N$）的组合。系统的配置是处理器状态向量和通信寄存器值向量的组合。

**The task $ST$ of legitimate sequences is defined as the set of all configuration sequences in which every configuration encodes a *BFS* tree of the communication graph. In fact, a particular *BFS* tree called the *first BFS tree* is encoded.** Let $α = (α_1, α_2, ...α_n)$ be the arbitrary ordering of the edges incident to each node $v_i ∈ V$. The first *BFS* tree of a communication graph $G$ is uniquely defined by the choice of the root $v_1$ and $α$. When a node $v_i$ of distance $x +1$ from $v_1$ has more than a single neighbor of distance $x$ from $v_1$, **$v_i$ is connected to its first neighbor according to $α_i$**, whose distance from $v_1$ is $x$. In the lemma below, we use the definition of the first *BFS* tree to characterize the set of safe configurations for the algorithm.

**合法序列任务 $ST$ 定义为所有配置序列的集合，其中每个配置都编码了通信图的一个 *BFS* 树。实际上，编码的是一个特定的 *BFS* 树，称为 *第一个 BFS 树*。**设 $α = (α_1, α_2, ...α_n)$ 为每个节点 $v_i ∈ V$ 的边的任意排序。通信图 $G$ 的 *第一个 BFS 树* 由根 $v_1$ 和 $α$ 唯一定义。当距离 $v_1$ 为 $x + 1$ 的节点 $v_i$ 有多个距离 $v_1$ 为 $x$ 的邻居时，**$v_i$ 根据 $α_i$ 连接到其第一个邻居**，该邻居距离 $v_1$ 为 $x$。在下面的引理中，我们使用第一个 *BFS* 树的定义来描述算法的一组安全配置。

The lemma below shows that, in every execution, a safe configuration is reached. **We use $\triangle$ to denote the maximum number of links adjacent to a processor**, and use the following definitions of *floating distances* and *smallest floating distance* in our proof.

下面的引理表明，在每次执行中，都会达到一个安全配置。**我们用 $\triangle$ 表示与处理器相邻的最大链接数**，并在证明中使用以下 *浮动距离* 和 *最小浮动距离* 的定义。

---

> DEFINITION 2.1: A floating distance in some configuration c is a value in a register $r_{ij}.dis$ that is smaller than the distance of $P_i$ from the root. The smallest floating distance in some configuration $c$ is the smallest value among the floating distances.
>
> 定义 2.1：在某个配置 $c$ 中，浮动距离是寄存器 $r_{ij}.dis$ 中的一个值，该值小于 $P_i$ 到根的距离。在某个配置 $c$ 中，最小浮动距离是浮动距离中的最小值。

---

> LEMMA 2.1: For every $k > 0$ and for every configuration that follows $\triangle+ 4k\triangle$ rounds, it holds that:
>
> *Assertion 1:* If there exists a floating distance, then the value of the smallest floating distance is at least $k$.
>
> *Assertion 2:* The value in the registers of every processor that is within distance $k$ from the root is equal to its distance from the root.
>
> 引理 2.1：对于每个 $k > 0$ 和每个经过 $\triangle+ 4k\triangle$ 轮次后的配置，满足以下条件：
>
> *断言 1：*如果存在浮动距离，那么最小浮动距离的值至少为 $k$。
>
> *断言 2：*每个距离根为 $k$ 以内的处理器的寄存器中的值等于其与根的距离。

*Proof:*

Note that in every $2\triangle$ successive rounds, each processor reads the registers of all its neighbors and writes to each of its registers. We prove the lemma by induction over $k$.

*Base case:*

(proof for $k = 1$) Distances stored in the registers and internal variables are non-negative; thus the value of the smallest floating distance is at least 0 in the first configuration. During the first $2\triangle$ rounds, each non-root processor $P_i$ computes the value of the variable $dist$ (line 7 of the code in figure 2.1). The result of each such computation must be greater than or equal to 1. Let $c_2$ be the configuration reached following the first computation of the value of $dist$ by each processor. Each non-root processor writes to each of its registers the computed value of $dist$ during the $2\triangle$ rounds that follow $c_2$. Thus, in every configuration that follows the first $4\triangle$ rounds there is no non-root processor with value 0 in its registers. The above proves assertion 1.

To prove assertion 2, note that the root repeatedly writes the distance 0 to its registers in every $\triangle$ rounds. Let $c_1$ be the configuration reached after these $\triangle$ rounds. Each processor reads the registers of the root and then writes to its own registers during the $4\triangle$ rounds that follow $c_1$. In this write operation the processor assigns 1 to its own registers. Any further read of the root registers returns the value 0; therefore, the value of the registers of each neighbor of the root is 1 following the first $\triangle+ 4\triangle$ rounds. Thus, assertion 2 holds as well.

*Induction step:*

(assume correctness for $k ≥ 0$ and prove for $k + 1$) Let $m ≥ k$ be the smallest floating distance in the configuration $c_{4k}$ that follows the first $\triangle+ 4k\triangle$ rounds. During the $4\triangle$ rounds that follow $c_{4k}$, each processor that reads $m$ and chooses $m$ as the smallest value assigns $m + 1$ to its distance and writes this value. Therefore, the smallest floating distance value is $m +1$ in the configuration $c_{4(k+1)}$. This proves assertion 1.

Since the smallest floating distance is $m ≥ k$, it is clear that each processor reads the distance of a neighboring processor of distance $k$ and assigns $k + 1$ to its distance. (End)

*证明：*

注意，在每 $2\triangle$ 连续轮次中，每个处理器读取其所有邻居的寄存器并写入其每个寄存器。我们通过对 $k$ 进行归纳来证明这个引理。

*基本情况：*

（证明 $k = 1$）寄存器和内部变量中存储的距离是非负的；因此，在第一个配置中，最小浮动距离的值至少为 0。在前 $2\triangle$ 轮次中，每个非根处理器 $P_i$ 计算变量 $dist$ 的值（图 2.1 中代码的第 7 行）。每次这样的计算结果必须大于或等于 1。设 $c_2$ 为每个处理器首次计算 $dist$ 值后的配置。在 $c_2$ 之后的 $2\triangle$ 轮次中，每个非根处理器将计算出的 $dist$ 值写入其每个寄存器。因此，在前 $4\triangle$ 轮次之后的每个配置中，没有非根处理器的寄存器值为 0。以上证明了断言 1。

为了证明断言 2，注意根在每 $\triangle$ 轮次中反复将距离 0 写入其寄存器。设 $c_1$ 为这些 $\triangle$ 轮次后的配置。每个处理器读取根的寄存器，然后在 $c_1$ 之后的 $4\triangle$ 轮次中将其写入自己的寄存器。在此写操作中，处理器将 1 赋给其自己的寄存器。任何进一步读取根寄存器的操作都会返回值 0；因此，在前 $\triangle+ 4\triangle$ 轮次之后，每个根邻居的寄存器值为 1。因此，断言 2 也成立。

*归纳步骤：*

（假设 $k ≥ 0$ 时正确，并证明 $k + 1$ 时正确）设 $m ≥ k$ 为前 $\triangle+ 4k\triangle$ 轮次后的配置 $c_{4k}$ 中的最小浮动距离。在 $c_{4k}$ 之后的 $4\triangle$ 轮次中，每个读取 $m$ 并选择 $m$ 作为最小值的处理器将 $m + 1$ 赋给其距离并写入该值。因此，在配置 $c_{4(k+1)}$ 中，最小浮动距离值为 $m +1$。这证明了断言 1。

由于最小浮动距离为 $m ≥ k$，显然每个处理器读取距离为 $k$ 的邻居处理器的距离并将其距离赋值为 $k + 1$。（完）

---

The next corollary is implied by lemma 2.1. Note that once the value in the registers of every processor is equal to its distance from the root, a processor $P_i$ chooses its parent to be the parent in the first *BFS* tree — $P_i$ chooses the first neighbor according to $α_i$, with distance smaller than its own.

下一个推论由引理 2.1 推导得出。注意，一旦每个处理器的寄存器中的值等于其与根的距离，处理器 $P_i$ 会选择其父节点为第一个 *BFS* 树中的父节点——$P_i$ 根据 $α_i$ 选择第一个距离小于其自身距离的邻居。

---

> COROLLARY 2.1: The algorithm presented above is self-stabilizing for $ST$.
>
> 推论 2.1：上述算法对于 $ST$ 是自稳定的。

## 2.6 Example: Mutual Exclusion

Dijkstra, in his  pioneering work, presented three elegant, self-stabilizing algorithms for mutual exclusion on a ring. Dijkstra’s work is considered to be the first to introduce and demonstrate the self-stabilization concept.

Dijkstra 在他的开创性工作中，提出了三个用于环形结构互斥的优雅的自稳定算法。Dijkstra 的工作被认为是首次引入和展示自稳定概念的研究。

The algorithms presented by Dijkstra are for a system in which **processors are activated by a scheduler called *central daemon*, which activates one processor at a time to execute an *aggregate step* consisting of several communication operations**. For simplicity we assume that the central daemon is *fair*, activating each processor infinitely often in every infinite execution. The activated processor uses its own state and the states of its neighbors to compute its next state. In other words, the central daemon chooses one processor at a time and lets this processor read the state (that is written in the registers) of its neighbors and change the state (write the new state in the communication registers). Thus, when describing a system configuration there is no need to consider local variables that store the values read from neighbors — the state transition is made according to the values stored in the registers of the neighbors when the (single) processor is scheduled.

Dijkstra 提出的算法适用于由称为 ***中央守护进程* 的调度程序激活处理器的系统**，该调度程序**一次激活一个处理器以执行由多个通信操作组成的 *聚合步骤***。为简单起见，我们假设中央守护进程是 *公平* 的，在每个无限执行中无限次激活每个处理器。被激活的处理器使用自己的状态和其邻居的状态来计算其下一个状态。换句话说，中央守护进程一次选择一个处理器，并让该处理器读取其邻居的状态（写在寄存器中）并改变状态（将新状态写入通信寄存器）。因此，在描述系统配置时，无需考虑存储从邻居读取值的局部变量——状态转换是根据调度时邻居寄存器中存储的值进行的。

The system consists of $n$ processors $P_1, P_2,··· , P_n$ that are connected in a ring. Each processor has a *left* and a *right* neighbor. The left neighbor of every processor $P_i$, $1 < i ≤ n$, is  $P_{i −1}$ and the left neighbor of $P_1$ is $P_n$. Similarly, the right neighbor of every processor $P_i$ , $1 ≤ i < n$, is  $P_{i +1}$ and the right neighbor of $P_n$ is $P_1$.

系统由 $n$ 个处理器 $P_1, P_2,··· , P_n$ 组成，这些处理器连接成一个环。每个处理器都有一个左邻居和一个右邻居。每个处理器 $P_i$ 的左邻居（$1 < i ≤ n$）是 $P_{i−1}$，而 $P_1$ 的左邻居是 $P_n$。同样，每个处理器 $P_i$ 的右邻居（$1 ≤ i < n$）是 $P_{i+1}$，而 $P_n$ 的右邻居是 $P_1$。

Each processor $P_i$ has a variable $x_i$ that stores an integer value that is no smaller than 0 and no larger than $n$. The transition functions of the processors $P_2,··· , P_n$ are identical, while the transition function of $P_1$ is distinct. We call $P_1$ the *special processor*. The transition functions (or programs) of $P_1$ and the other processors $P_i$ ($2 ≤ i ≤ n$) appear in figure 2.2.

每个处理器 $P_i$ 有一个变量 $x_i$，该变量存储一个不小于 0 且不大于 $n$ 的整数。处理器 $P_2,··· , P_n$ 的转换函数是相同的，而 $P_1$ 的转换函数是不同的。我们称 $P_1$ 为 *特殊处理器*。$P_1$ 和其他处理器 $P_i$（$2 ≤ i ≤ n$）的转换函数（或程序）如图 2.2 所示。

![figure_2.2](images/figure_2.2.png)

A configuration of the system is a vector of $n$ integer values, one value for each $x$ variable. A computation step of a processor $P_i$ consists of reading the $x$ variable of the left neighbor and using the value obtained together with the value of xi to compute a new value for $x_i$. **At any given time, only a single processor is executing a computation step.** A processor $P_i$ *can change its state* in a particular configuration $c$ if the next computation step of $P_i$ (when started in $c$) changes the value of $x_i$; i.e., $x_i \neq x_{i−1}$ in $c$, or $x_1 = x_n$ in $c$.

系统的配置是一个包含 $n$ 个整数值的向量，每个 $x$ 变量对应一个值。处理器 $P_i$ 的计算步骤包括读取左邻居的 $x$ 变量，并使用获得的值与 $x_i$ 的值一起计算 $x_i$ 的新值。**在任何给定时间，只有一个处理器在执行计算步骤。**如果处理器 $P_i$ 的下一个计算步骤（从配置 $c$ 开始时）改变了 $x_i$ 的值，则处理器 $P_i$ 可以在特定配置 $c$ 中 *改变其状态*；即在配置 $c$ 中，$x_i \neq x_{i−1}$，或 $x_1 = x_n$。

The task $ME$ is defined by the set of all configuration sequences in which exactly one processor can change its state in any configuration and every processor can change its state in infinitely many configurations in every sequence in $ME$. Note that this definition differs from the traditional definition of mutual exclusion that allows processors to be in the reminder section (possibly forever) as long as they do not try to enter the critical section.

**任务 $ME$ 的定义是：它是满足这样一些要求的，所有的配置序列的集合，其中在任何配置中恰好有一个处理器可以改变其状态，并且在 $ME$ 中的每个序列中，每个处理器都可以在无限多个配置中改变其状态。**请注意，这一定义不同于传统的互斥定义，传统定义允许处理器在提醒区（可能永远）中，只要它们不尝试进入临界区。

A safe configuration for $ME$ and Dijkstra’s algorithm (figure 2.2) is a configuration in which all the $x$ variables have the same value. This is only one example of a safe configuration, but sufficient for what we need. The next lemma proves that, indeed, every fair execution that starts with such a safe configuration belongs to $ME$.

对于任务 $ME$ 和 Dijkstra 的算法（图 2.2），一个安全配置是所有 $x$ 变量具有相同值的配置。这只是一个安全配置的例子，但足以满足我们的需要。下一个引理证明，确实，每个从这种安全配置开始的公平执行都属于 $ME$。

---

> LEMMA 2.2: A configuration $c$ in which all the $x$ variables have the same value is a safe configuration for $ME$ and Dijkstra’s algorithm.
>
> **引理 2.2**：在配置 $c$ 中，如果所有 $x$ 变量具有相同的值，则该配置对于 $ME$ 和 Dijkstra 算法来说是安全的配置。

*Proof:*

Clearly the only processor $P_i$ that is able to change the value of $x_i$ in $c$ is $P_1$. $P_1$ is activated infinitely often in every fair execution that starts in c. Once $P_1$ is activated, $P_1$ assigns $x_1$ a value that does not exist in any other variable. Let $c_1$ be the configuration that immediately follows the assignment of this new value in $x_1$. Clearly, $P_1$ cannot change the value of $x_1$ until $x_n$ holds the new value as well.

Every other processor $P_i$ cannot change the value of $x_i$ unless $x_{i−1} \neq x_i$. Thus, the only processor $P_i$ that can change the value of $x_i$ is $P_2$. $P_2$ is activated infinitely often in every fair execution, and in particular it is activated infinitely often following $c_1$ of every fair execution.

Let $c_2$ be the configuration reached immediately after $P_2$ changes the value of $x_2$. In $c_2$, it holds that $x_1 = x_2$, $x_2 \neq x_3$, and $x_3 = x_4 = ··· = x_n$. Thus, the only processor that is able to change a state is $P_3$.

In general, in $c_i$ , $1 ≤ i < n$, it holds that $x_1 = x_2 = ··· = x_i$, $x_i \neq x_{i+1}$, and $x_{i+1} = x_{i+2} = ··· = x_n$. Thus, the only processor that is able to change the value of its variable is  $P_{i +1}$.

Therefore, in $c_{n−1}$, only $P_n$ is able to change the value of its variable and, once it is activated, a configuration $c_n$ is reached in which the values of all the variables are the same. Note that in every execution that starts in $c$ and ends in $c_n$ exactly one processor is able to change the value of its variable and each processor changes the value of its variable exactly once.

Exactly the same arguments can be applied to $c_n$; thus it is clear that, in every fair execution, every processor changes the value of its variable infinitely often and, in every execution, there is exactly one processor that can change its state. (End)

*证明：*

显然，在配置 $c$ 中，唯一能够改变 $x_i$ 值的处理器 $P_i$ 是 $P_1$。在每个从 $c$ 开始的公平执行中，$P_1$ 被无限次激活。一旦 $P_1$ 被激活，$P_1$ 会为 $x_1$ 分配一个在其他变量中不存在的值。设 $c_1$ 为在 $x_1$ 分配新值后立即跟随的配置。显然，$P_1$ 不能改变 $x_1$ 的值，直到 $x_n$ 也持有新值。

每个其他处理器 $P_i$ 不能改变 $x_i$ 的值，除非 $x_{i−1} \neq x_i$。因此，唯一能够改变 $x_i$ 值的处理器 $P_i$ 是 $P_2$。在每个公平执行中，$P_2$ 被无限次激活，特别是在每个公平执行的 $c_1$ 之后无限次激活。

设 $c_2$ 为 $P_2$ 改变 $x_2$ 值后立即达到的配置。在 $c_2$ 中，$x_1 = x_2$，$x_2 \neq x_3$，并且 $x_3 = x_4 = ··· = x_n$。因此，唯一能够改变状态的处理器是 $P_3$。

一般来说，在 $c_i$ 中，$1 ≤ i < n$，有 $x_1 = x_2 = ··· = x_i$，$x_i \neq x_{i+1}$，并且 $x_{i+1} = x_{i+2} = ··· = x_n$。因此，唯一能够改变其变量值的处理器是 $P_{i +1}$。

因此，在 $c_{n−1}$ 中，只有 $P_n$ 能够改变其变量的值，一旦它被激活，就会达到一个配置 $c_n$，其中所有变量的值都相同。注意，在每个从 $c$ 开始并以 $c_n$ 结束的执行中，只有一个处理器能够改变其变量的值，并且每个处理器恰好改变其变量的值一次。

完全相同的论点可以应用于 $c_n$；因此显然，在每个公平执行中，每个处理器无限次地改变其变量的值，并且在每个执行中，恰好有一个处理器能够改变其状态。（完）

---

To prove that Dijkstra’s algorithm is self-stabilizing for $ME$, we need to show that, in every fair execution, a safe configuration relative to $ME$ is reached after a finite number of rounds. We first observe that, in any possible configuration, at least one possible value for the $x$ variables does not exist. In fact, the observation that in any configuration at least one value is missing is used in what follows. We call this concept the *missing value* or *missing label concept*.

为了证明 Dijkstra 算法对 $ME$ 是自稳定的，我们需要证明在每个公平执行中，相对于 $ME$ 的安全配置在有限轮次后达到。我们首先观察到，**在任何可能的配置中，至少有一个 $x$ 变量的可能值不存在。**事实上，接下来将使用这一观察，即在任何配置中至少缺少一个值。我们称这一概念为 *缺失值* 或 *缺失标签概念*。

---

> LEMMA 2.3: For every possible configuration $c$, there exists at least one integer $0 ≤ j ≤ n$ such that for every $1 ≤ i ≤ n$, $x_i \neq j$ in $c$.
>
> **引理 2.3**：对于每一个可能的配置 $c$，存在至少一个整数 $0 ≤ j ≤ n$，使得对于每一个 $1 ≤ i ≤ n$，在配置 $c$ 中 $x_i \neq j$。

*Proof:*

There are at most $n$ distinct values in the $x$ variables in $c$, a distinct value for each processor $P_i$. There are $n + 1$ possible values that can be stored in each of the $x$ variables. Thus, an integer $j$ must exist that does not appear in any $x_i$. (End)

*证明：*

在配置 $c$ 中，$x$ 变量中最多有 $n$ 个不同的值，每个处理器 $P_i$ 对应一个不同的值。每个 $x$ 变量可以存储 $n + 1$ 个可能的值。因此，必须存在一个整数 $j$，它不会出现在任何 $x_i$ 中。（完）

---

The next observation is also simple, claiming that the special processor $P_1$ changes the value of $x_1$ infinitely often in every fair execution.

下一个观察也很简单，声称**特殊处理器 $P_1$ 在每个公平执行中无限次地改变 $x_1$ 的值**。

---

> LEMMA 2.4: For every possible configuration $c$, in every fair execution that starts in $c$, the special processor $P_1$ changes the value of $x_1$ at least once in every $n$ rounds.
>
> **引理 2.4**：对于每一个可能的配置 $c$，在每个从 $c$ 开始的公平执行中，特殊处理器 $P_1$ 在每 $n$ 轮中至少改变一次 $x_1$ 的值。

*Proof:*

Assume that there exists a configuration $c$ and a fair execution that starts in $c$ and in which $P_1$ does not change the value of $x_1$ during the first $n$ rounds.

- Let $c_2$ be the configuration that immediately follows the first time $P_2$ executes a computation step during the first round. Clearly, $x_1 = x_2$ in $c_2$ and in every configuration that follows $c_2$ in the next $n − 1$ rounds.
- Let $c_3$ be the configuration that immediately follows the first time $P_3$ executes a computation step during the second round. It holds in $c_3$ that $x_1 = x_2 = x_3$.
- The same argument repeats itself until we arrive at the configuration $c_n$, which is reached in the ($n − 1$) th round and in which $x_1 = x_2 =···= x_n$.

In the $n$ th round, $P_1$ is activated and changes the value of $x_1$, a contradiction. (End)

*证明：*

**假设**存在一个配置 $c$ 和一个从 $c$ 开始的公平执行，在该执行中 $P_1$ 在前 $n$ 轮中没有改变 $x_1$ 的值。

- 设 $c_2$ 为 $P_2$ 在第一轮中第一次执行计算步骤后立即跟随的配置。显然，在 $c_2$ 中 $x_1 = x_2$，并且在接下来的 $n − 1$ 轮中每个跟随 $c_2$ 的配置中也是如此。
- 设 $c_3$ 为 $P_3$ 在第二轮中第一次执行计算步骤后立即跟随的配置。在 $c_3$ 中，$x_1 = x_2 = x_3$。
- 同样的论点重复，直到我们到达配置 $c_n$，该配置在第 ($n − 1$) 轮中达到，并且在该配置中 $x_1 = x_2 =···= x_n$。

在第 $n$ 轮中，$P_1$ 被激活并改变 $x_1$ 的值，这与假设矛盾。（完）

---

**We are now ready to prove the main theorem.**

我们现在准备证明主要定理。

---

> THEOREM 2.1: For every possible configuration $c$, every fair execution that starts in $c$ reaches a safe configuration with relation to $ME$ within $O(n^2)$ rounds.
>
> **定理 2.1**：对于每一个可能的配置 $c$，每个从 $c$ 开始的公平执行在 $O(n^2)$ 轮内达到相对于 $ME$ 的安全配置。

*Proof:*

In accordance with lemma 2.3, for every possible configuration $c$ there exists at least one integer $0 ≤ j ≤ n$ such that, for every $1 ≤ i ≤ n$, $x_i \neq j$ in $c$.

In accordance with lemma 2.4, for every possible configuration $c$, in every fair execution that starts in $c$, the special processor $P_1$ changes the value of $x_1$ in every $n$ rounds.

Every time $P_1$ changes the value of $x_1$, $P_1$ increments the value of $x_1$ modulo $n + 1$.

Thus, it must hold that every possible value, and in particular the value $j$, is assigned to $x_1$ during any fair execution that starts in $c$. Let $c_j$ be the configuration that immediately follows the first assignment of $j$ in $x_1$.

Every processor $P_i (2 ≤ i ≤ n)$ copies the value of $x_{i−1}$ to $x_i$ . Thus, it holds for $1 ≤ i ≤ n$ that $x_i \neq j$ in every configuration that follows $c$ and precedes $c_j$; it also holds that in $c_j$ , the only $x$ variable that holds the value $j$ is $x_1$. $P_1$ does not change the value of $x_1$ until $x_n = j$.

The only possible sequence of changes of the values of the $x$ variables to the value $j$ is: $P_2$ changes $x_2$ to the value of $x_1$ (which is $j$), then $P_3$ changes the value of $x_3$ to $j$ and so on until $P_n$ changes the value of $x_n$ to $j$. Only at this stage is $P_1$ able to change value again (following $c_j$). Let $c_n$ be the configuration reached following the assignment of $x_n := j$. $c_n$ is a safe configuration.

In accordance with lemma 2.4, $P_1$ must assign $j$ to $x_1$ in every $n^2$ rounds. Thus a safe configuration must be reached in $n^2 + n$ rounds. (End)

*证明：*

根据引理 2.3，对于每一个可能的配置 $c$，存在至少一个整数 $0 ≤ j ≤ n$，使得对于每一个 $1 ≤ i ≤ n$，在配置 $c$ 中 $x_i \neq j$。

根据引理 2.4，对于每一个可能的配置 $c$，在每个从 $c$ 开始的公平执行中，特殊处理器 $P_1$ 在每 $n$ 轮中改变一次 $x_1$ 的值。

每次 $P_1$ 改变 $x_1$ 的值时，$P_1$ 将 $x_1$ 的值按模 $n + 1$ 增加。

因此，在从 $c$ 开始的任何公平执行中，$x_1$ 必定会被分配到每一个可能的值，特别是值 $j$。设 $c_j$ 为 $x_1$ 首次分配值 $j$ 后立即跟随的配置。

每个处理器 $P_i$ ($2 ≤ i ≤ n$) 将 $x_{i−1}$ 的值复制到 $x_i$。因此，对于 $1 ≤ i ≤ n$，在每个跟随 $c$ 并先于 $c_j$ 的配置中，$x_i \neq j$；在 $c_j$ 中，唯一持有值 $j$ 的 $x$ 变量是 $x_1$。$P_1$ 不会改变 $x_1$ 的值，直到 $x_n = j$。

唯一可能的将 $x$ 变量的值改变为 $j$ 的序列是：$P_2$ 将 $x_2$ 的值改变为 $x_1$ 的值（即 $j$），然后 $P_3$ 将 $x_3$ 的值改变为 $j$，依此类推，直到 $P_n$ 将 $x_n$ 的值改变为 $j$。只有在这个阶段，$P_1$ 才能再次改变值（跟随 $c_j$）。设 $c_n$ 为 $x_n := j$ 分配后的配置。$c_n$ 是一个安全配置。

根据引理 2.4，$P_1$ 必须在每 $n^2$ 轮中将 $j$ 分配给 $x_1$。因此，安全配置必须在 $n^2 + n$ 轮内达到。（完）

---

In fact, Dijkstra’s algorithm stabilizes when the number of possible values for the $x$ variable is $n$. The reason is that, if no possible value is missing in the first configuration, then $x_1$ has a distinct value; thus, stabilization is guaranteed. Otherwise, at least one possible value is missing in the first configuration and theorem 2.1 holds.

事实上，当 $x$ 变量的可能值数量为 $n$ 时，Dijkstra 算法会稳定下来。原因是，如果在初始配置中没有缺失的可能值，那么 $x_1$ 就有一个独特的值；因此，稳定性是有保证的。否则，在初始配置中至少缺少一个可能值，并且定理 2.1 成立。

Moreover, a similar argument holds when the number of possible values for the x variables is $n − 1$. In this case, a configuration must be reached in which $x_n = x_1$ (just before the first time $P_1$ changes the value of $x_1$). Call this configuration $c$. If in c every processor $P_i$, $1 ≤ i ≤ n − 1$, does not hold a distinct value in xi , then a missing value $j$ must exist and the stabilization is proved by a proof similar to that of theorem 2.1. Otherwise, each $P_i$, $1 ≤ i ≤ n − 1$, holds a distinct value in $c$. Let $j'$ be the value of $x_1$ in $c$ and consider the first configuration $c'$ that follows c and in which $P_1$ is able to change the value of $x_1$. Consider the following three cases for the first computation step that follows $c$.

Case 1: a processor $P_i$, $2 ≤ i ≤ n − 1$, copies the value of $x_{i−1}$ to $x_i$ and, at the same time, eliminates the distinct value stored in xi from the system.

Case 2: $P_n$ copies the distinct value of $x_{n−1}$ to $x_n$, leaving $x_1$ with a distinct value.

Case 3: $P_1$ changes the value of $x_1$ to $k = (j'+1) \mod (n−1)$; thus, the only x variable that holds $j'$ is $x_n$. However, $P_n$ must copy the value $k$ within the next $n$ rounds (before $P_1$ changes the value of $x_1$ again), eliminating $j'$ from the system.

此外，当 $x$ 变量的可能值数量为 $n − 1$ 时，类似的论点也成立。在这种情况下，必须达到一个配置，其中 $x_n = x_1$（就在 $P_1$ 第一次改变 $x_1$ 的值之前）。称此配置为 $c$。如果在 $c$ 中，每个处理器 $P_i$（$1 ≤ i ≤ n − 1$）在 $x_i$ 中没有持有一个独特的值，那么必须存在一个缺失值 $j$，并且通过类似于定理 2.1 的证明可以证明稳定性。否则，每个 $P_i$（$1 ≤ i ≤ n − 1$）在 $c$ 中持有一个独特的值。设 $j'$ 为 $c$ 中 $x_1$ 的值，并考虑紧随 $c$ 之后的第一个配置 $c'$，在该配置中 $P_1$ 能够改变 $x_1$ 的值。考虑以下三种情况，作为紧随 $c$ 之后的第一个计算步骤。

情况 1：处理器 $P_i$（$2 ≤ i ≤ n − 1$）将 $x_{i−1}$ 的值复制到 $x_i$，同时从系统中消除存储在 $x_i$ 中的独特值。

情况 2：$P_n$ 将 $x_{n−1}$ 的独特值复制到 $x_n$，使 $x_1$ 保持一个独特的值。

情况 3：$P_1$ 将 $x_1$ 的值改变为 $k = (j'+1) \mod (n−1)$；因此，唯一持有 $j'$ 的 $x$ 变量是 $x_n$。然而，$P_n$ 必须在接下来的 $n$ 轮内复制值 $k$（在 $P_1$ 再次改变 $x_1$ 的值之前），从系统中消除 $j'$。

Will Dijkstra’s algorithm stabilize when the number of possible values for the $x$ variables is $n − 2$ ? Let $c$ = {0, 0, 2, 1, 0} be a system configuration. An execution that starts in $c$ and repeatedly activates $P_1$, $P_5$, $P_4$, $P_3$, $P_2$, in this order, does not reach a safe configuration:

Dijkstra 算法是否会在 $x$ 变量的可能值数量为 $n − 2$ 时稳定？设 $c$ = {0, 0, 2, 1, 0} 为一个系统配置。从 $c$ 开始并按顺序重复激活 $P_1$、$P_5$、$P_4$、$P_3$、$P_2$ 的执行不会达到安全配置：

{0, 0, 2, 1, 0}→{1, 0, 2, 1, 0}→{1, 0, 2, 1, 1}→{1, 0, 2, 2, 1}→{1, 0, 0, 2, 1}→{1, 1, 0, 2, 1}···

Note that the configuration {1, 1, 0, 2, 1}is obtained by incrementing every value in {0, 0, 2, 1, 0} by 1, where the increment operation is done modulo $n − 2 = 3$, and therefore the configuration {0, 0, 2, 1, 0} is reached again after activating each processor $n − 2 = 3$ times when the processors are repeatedly activated in the order specified above. Thus, there exists an infinite execution in which more than one processor can change a state in every configuration. This execution has no suffix in $ME$, and therefore the algorithm is not self stabilizing with relation to $ME$.

注意，配置 {1, 1, 0, 2, 1} 是通过将 {0, 0, 2, 1, 0} 中的每个值增加 1 获得的，其中增加操作是以模 $n − 2 = 3$ 进行的，因此在按上述顺序重复激活每个处理器 $n − 2 = 3$ 次后，配置 {0, 0, 2, 1, 0} 再次达到。因此，存在一个无限执行，其中在每个配置中有多个处理器可以改变状态。这个执行在 $ME$ 中没有后缀，因此该算法相对于 $ME$ 不是自稳定的。

It seems at first glance that the powerful central daemon scheduler guarantees some sort of mutual exclusion by activating one processor at a time. One can ask whether an algorithm in which every processor $P_i$ executes the critical section (whenever the central daemon activates $P_i$) is a mutual exclusion algorithm.

听起来强大的中央守护进程调度器通过每次激活一个处理器来保证某种互斥。有人可能会问，一个算法中，每当中央守护进程激活处理器 $P_i$ 时，该处理器 $P_i$ 执行临界区，这是否是一个互斥算法。

To answer the above question, let us consider a multitasking single-processor computer in which, at any given time, exactly one process is executed by the single processor. In such settings, one of the processes $P_i$ may enter the critical section (e.g., may start using a resource such as the printer). $P_i$ may be suspended while it is in the critical section by the operating system, due to task switching. We would not want any other process to enter the critical section (and, say, start printing) as long as $P_i$ is in the critical section. Clearly, Dijkstra’s algorithm can be used to coordinate the activity of the processes in such a system in the following way: the single process $P_i$ that can change a state is the one that may access the critical section. Only when process $P_i$ is finished with the critical section does it change the value of $x_i$.

要回答上述问题，让我们考虑一个多任务单处理器计算机，在任何给定时间内，单处理器只执行一个进程。在这种情况下，某个进程 $P_i$ 可能会进入临界区（例如，开始使用资源如打印机）。$P_i$ 可能会因为操作系统的任务切换而在临界区内被挂起。当 $P_i$ 在临界区时，我们不希望任何其他进程进入临界区（例如，开始打印）。显然，Dijkstra 的算法可以用来协调这样一个系统中的进程活动：可以改变状态的单个进程 $P_i$ 是唯一可以访问临界区的进程。只有当进程 $P_i$ 完成临界区的操作后，它才会改变 $x_i$ 的值。

On the negative side, we demonstrate that Dijkstra’s algorithm needs more states to work if steps consists of only one communication operation, read or write. (The term *read/write* *atomicity* describes the operations in such a system.) To do this we introduce an internal variable $l_{xi}$ for every processor $P_i$ in which is stored the last value read by $P_i$ from the $x$ variable of the left neighbor of $P_i$. Note that the existence of such a variable is enforced by the new atomicity, since a write operation is not executed in the same atomic step as a read operation and the value written is a function of the last value read. Now a possible configuration is a vector  $c = \{(l_{x1}, x1), (l_{x2}, x2),··· , (l_{xn}, xn)\}$. A read operation of $P_i$, $1 < i ≤ n$, copies the value of $x_{i−1}$ into $l_{xi}$; a read operation of $P_1$ copies the value of $x_n$ into $l_{x1}$. A write operation of $P_i$, $1 < i ≤ n$, copies the value of $l_{xi}$ into $x_i$; a write operation of $P_1$ assigns $(l_{x1} + 1) \mod K$ to $x_1$, where, from our previous discussion, $K > (n − 2)$. If we reexamine the operation of every processor in the read/write atomicity model, we discover that the n−processor ring in this model is identical to a ring of $2n$ processors in a system with a central daemon. A read operation is essentially a copy of the value of the left neighbor. A write operation by every processor $P_i$, $i \neq 1$, is also a copy operation from $l_{xi}$ to $x_i$. $x_1$ is the only variable that is incremented modulo $K$ during a write operation. Thus, we can apply our previous proofs and discussion to conclude that $K$ must be greater than $2n − 2$.

在负面方面，我们证明了如果步骤仅由一个通信操作（读取或写入）组成，Dijkstra 算法需要更多的状态才能工作。（术语 *读/写原子性* 描述了这种系统中的操作。）为此，我们为每个处理器 $P_i$ 引入一个内部变量 $l_{xi}$，其中存储了 $P_i$ 从其左邻居的 $x$ 变量中读取的最后一个值。注意，这种变量的存在是由新的原子性强制要求的，因为写操作并不是在与读操作相同的原子步骤中执行的，并且写入的值是最后读取值的函数。现在，可能的配置是一个向量 $c = \{(l_{x_1}, x_1), (l_{x_2}, x_2),··· , (l_{x_n}, x_n)\}$。$P_i$ 的读操作，$1 < i ≤ n$，将 $x_{i−1}$ 的值复制到 $l_{x_i}$；$P_1$ 的读操作将 $x_n$ 的值复制到 $l_{x_1}$。$P_i$ 的写操作，$1 < i ≤ n$，将 $l_{x_i}$ 的值复制到 $x_i$；$P_1$ 的写操作将 $(l_{x_1} + 1) \mod K$ 赋给 $x_1$，根据我们之前的讨论，$K > (n − 2)$。如果我们重新检查在读/写原子性模型中每个处理器的操作，我们会发现该模型中的 $n$ 处理器环与带有中央守护进程的系统中的 $2n$ 处理器环是相同的。读操作本质上是左邻居值的复制。每个处理器 $P_i$（$i \neq 1$）的写操作也是从 $l_{x_i}$ 到 $x_i$ 的复制操作。$x_1$ 是唯一在写操作期间以模 $K$ 增加的变量。因此，我们可以应用之前的证明和讨论，得出 $K$ 必须大于 $2n − 2$。

In figure 2.3 circles represent processors and rectangles represent communication registers. The left portion of figure 2.3 represents a system for which read/write atomicity is assumed. The arrows in the left portion denote the ability of $P_i$ to write (the value of $l_{xi}$, if $i \neq 1$) in $x_i$ and read the value of $x_{i−1}$  (into $l_{xi}$). The right portion of figure 2.3 represents a system for which a central daemon is assumed. The arrows in this portion denote the ability of $P_i$ to use the state of its left neighbor together with its own state for its transition function. Note that there is no need to store a value read from a (register of a) processor in a local variable. Whenever the central daemon schedules a processor to execute a step, the state of the left neighbor (the value read from the left neighbor) is used by $P_i$ in the very same (aggregate) step to compute its next state.
在图 2.3 中，圆圈表示处理器，矩形表示通信寄存器。图 2.3 的左部分表示假定具有读/写原子性的一种系统。左部分中的箭头表示 $P_i$ 能够在 $x_i$ 中写入值（$l_{x_i}$ 的值，如果 $i \neq 1$）并读取 $x_{i−1}$ 的值（到 $l_{xi}$ 中）。图 2.3 的右部分表示假定具有中心守护进程的一种系统。此部分中的箭头表示 $P_i$ 能够使用其左邻居的状态及其自身的状态来进行状态转换函数。请注意，不需要将从（一个处理器的寄存器）读取的值存储在局部变量中。每当中心守护进程安排处理器执行一个步骤时，左邻居的状态（从左邻居读取的值）在同一个（聚合）步骤中由 $P_i$ 使用来计算其下一个状态。

![figure_2.3](images/figure_2.3.png)

## 2.7 Fair Composition of Self-Stabilizing Algorithms
