# 2.10 Pseudo-Self-Stabilization

To describe the pseudo-self-stabilizing concept, let us start with an example. A computer company found a new technology for personal computers. The cost of a computer produced by this company is much lower than that of other computers. However, the computer has one drawback: it is possible that it will spontaneously turn itself off during operation. The company guarantees that the number of shutdowns is limited to seven, but does not promise if and when they will take place. The customer might choose such a cheap computer because the electricity power supply is not in any case reliable and cannot guarantee continuous operation. Analogously, pseudo self-stabilizing algorithms converge from any initial state to execution, in which they exhibit a legal behavior; but they still may deviate from this legal behavior a finite number of times. A more formal treatment of the pseudo-self stabilizing concept follows.

We defined a self-stabilizing algorithm as an algorithm for which every fair execution must reach a safe configuration. Since every execution that starts in a safe configuration is a legal execution belonging to $LE$, it is the case that, once a safe configuration is reached, the system behaves as desired.

The set of legal executions $LE$ defines the desired behavior of the system. In fact, defining the requirements by a set of executions $LE$ is sometimes too restrictive. $A$ task $T$ may be defined in a more abstract way, avoiding the definitions and the description of the implementation details. The variables used by the specific distributed algorithm to achieve the task are not part of this task specification. An *abstract task* is defined by a set of variables and a set of restrictions on their values. For example, let us define the token passing abstract task $\mathcal{AT}$ for a system of two processors: the sender $S$ and the receiver $R$. $S$ has a boolean variable ${token}_S$ and R has a boolean variable ${token}_R$.

Recall that a system execution is a sequence of configurations such that every configuration $c_{i+1}$ is obtained from the immediately preceding configuration $c_i$ by a single atomic step $a_i$ of a processor. The steps of the processors are defined by the distributed algorithm that the system runs. Given an execution of the system $E = (c_1, a_1, c_2, a_2,···)$, one may consider only the values of ${token}_S$ and ${token}_R$ in every configuration $c_i$ to check whether the token-passing task is achieved. Let $c_i|tkns$ be the values of the boolean variables $({token}_S, {token}_R)$ in $c_i$, and let $E|tkns$ be $(c_1|tkns, c_2|tkns, c_3|tkns,···)$. The abstract task $\mathcal{AT}$ can be defined by $E|tkns$ as follows: there is no $c_i|tkns$ for which ${token}_S = {token}_R = true$, and there are infinitely many is such that ${token}_S = true$ in $c_i|tkns$, and infinitely many $j$ s such that ${token}_R = true$ in $c_j|tkns$. In other words, each of the processors holds the token infinitely many times, but the processors never hold tokens simultaneously.

The above specification of the abstract task $\mathcal{AT}$ is a more general specification of the token-passing task than a definition by a legal set of executions $LE$; the reason is that $LE$ is defined for a specific distributed algorithm. On the other hand, it is impossible to define a safe configuration in terms of $c|tkns$. For instance, we cannot tell whether a configuration in which ${token}_S = true$ and ${token}_R = false$ is safe. The reason is that we ignore, say, the state variables of $R$ that specify whether $R$ is about to execute a step in which ${token}_R$ is assigned to true, while ${token}_S$ remains unchanged.

An algorithm is *pseudo-self-stabilizing* for an abstract task $\mathcal{AT}$ if every infinite execution of the algorithm has a suffix satisfying the restrictions of $\mathcal{AT}$.

Clearly a self-stabilizing algorithm for a task $LE$ such that every execution in $LE$ fulfills the restrictions of $\mathcal{AT}$ is pseudo-self-stabilizing. However, a pseudo self-stabilizing algorithm may not be self-stabilizing, since it may not reach a configuration such that for *every* execution that starts in it, the restrictions of $\mathcal{AT}$ hold.

Figure 2.12 depicts such a situation: nine configurations and the transitions between them are described. The upper four configurations form a cycle that corresponds to a possible infinite legal execution relative to the abstract task of token-passing. Each of the processors holds a token infinitely often, and at most one processor holds the token at a time. Similarly, the lower cycle of the four configurations in figure 2.12 also corresponds to an infinite legal execution. The configuration in the center of the figure is illegal, since both the processors have a token at the same time. The transition to this configuration may arise from, say, a message loss: only if a message is lost is the transition to the configuration in which both the sender and the receiver hold the token possible. In other words, if no message is lost, the execution depicted by the upper cycle is an infinite legal execution relative to the abstract task $\mathcal{AT}$. Yet the system is not in a safe configuration, and there is no time bound for reaching a safe configuration. Only after a message is lost does the system reach the lower cycle of figure 2.12 and, indeed, a safe configuration.

![figure_2.12](images/figure_2.12.png)

To demonstrate pseudo-self-stabilization, we use the famous alternating-bit algorithm, one of the most basic data-link algorithms used for message transfer over a communication link. The common communication link is unreliable and may lose or corrupt messages. It is assumed that error-detection codes are used to identify and eliminate corrupted messages. We view each such discarded corrupted message as a lost message. The alternating-bit algorithm uses retransmission of messages to cope with message loss. When every corrupted message is identified and the communication links are FIFO (first-in first-out), the alternating-bit algorithm guarantees reliable delivery of (higher-level) messages over such an unreliable communication link. The term *frame* is used to distinguish the higher-level messages that must be transferred from the messages that are actually sent in order to transfer the higher-level messages; frames are the messages that are actually sent between the sender and the receiver. The algorithm is designed for a system consisting of two processors $S$ and $R$ that are connected by two communication links: one transfers frames from $S$ to $R$, and the other from $R$ to $S$.

![figure_2.13](images/figure_2.13.png)

The task of delivering a message from one processor in the network to another remote processor is sophisticated. It is usually partitioned into several layers of algorithms and abstractions: an algorithm of a certain layer uses the services of a lower-level algorithm. The lowest layer is the physical layer for which the concern is how the physical device connecting to neighboring processors is used to transmit bits from a processor to its neighbor. Usually the physical layer can ensure transmission of bits with a certain (small) error probability that each bit is corrupted. The next layer is the *data-link layer*, which assumes the existence of a (physical layer) procedure that transmits bits. The task of the data-link layer is to transmit messages from a processor to its neighbor. The data-link layer uses error-detection codes and retransmissions to cope with the probability of bit corruption (introduced by the physical communication device). The *network layer* task is to direct messages sent from one processor to a remote (non-neighboring) processor. Routing algorithms are used to maintain routing databases (routing tables). Whenever a processor must forward an arriving message, it consults the routing database to identify the outgoing link on which the message should be sent; then the data-link procedure of the chosen link is used. Several messages that have to be forwarded may arrive at a processor simultaneously (through its input communication ports). The arriving messages may be stored in input buffers (on a disk) and then *fetched* by the data-link layer algorithm. The data-link algorithm uses *frames* to *send* the fetched message. The data-link algorithm portion that is executed at the receiver receives the sent frames (and sends acknowledgment frames). When the data-link algorithm executed at the receiver side is convinced that the message is received, it *delivers* the message to be handled by the network layer algorithm at the receiver, which in turn consults its routing database.

Figure 2.13 describes the *fetch*, *send*, *receive*, and *deliver* operations. A queue of messages $(m_1, m_2, m_3,···)$ stored in a non-volatile memory are to be transmitted from the sender to the receiver. A fetch operation executed by the sender removes the first message of the queue and stores it in the (volatile) memory of the sender. Then the sender must transfer $m_1$ to the receiver. In the particular example in figure 2.13, the sender sends $m_1$ in the frame $f_1$. This is only one possibility; in fact, other data-link algorithms may send only partial information concerning $m_1$ in $f_1$. Note that in addition to the contents of $m_1$, $f_1$ may include control information, for example the label of the alternating-bit algorithm. Once the receiver receives $f_1$, it delivers $m_1$ to the output queue. Finally, the receiver sends the frame $f_2$ to the sender in order to notify it sender that a new message can be fetched.

The abstract task of the alternating-bit algorithm can be defined as follows. The sender $S$ has an infinite queue of input messages $({im}_1, {im}_2, ···)$ that should be transferred to the receiver in the same order without duplications, reordering, or omissions. The receiver has an output queue of messages $({om}_1,  {om}_2, ···)$. The sequence of messages in the output queue of the receiver should always be a prefix of the sequence of messages in the input queue of the sender. Moreover, to eliminate solutions in which no input message is transfered to the receiver, we require that infinitely often a new message is included in the output queue.

![figure_2.14](images/figure_2.14.png)

The alternating-bit algorithm in figure 2.14 is not a self-stabilizing algorithm: it is assumed that both the sender and the receiver perform the initialization instructions (lines 1 to 6 and 19 to 23) when the system starts operating. During the initialization the sender fetches the first message im1 from the buffer of the networks layer, and sends a frame with this message together with label 0 (the value of ${bit}_s$) to the receiver. A timeout mechanism copes with frame loss triggering frame retransmission (lines 7 and 8). Once the receiver executes the initialization procedure, it waits for a frame with label 0 (line 27) while acknowledging arriving frames. When a frame with a (new) label different from the current value of ${bit}_r$ arrives at the receiver, the receiver delivers the message of this frame to the network layer (line 31). The indices $i$ (line 15) and $j$ (line 30) are used only to describe the interface with the network layer. In fact, the input buffer from which ${im}_i$ is fetched is a queue from which messages are fetched without identifying their index. The first fetch operation (implicitly executed in line 5) fetches the first message in the input queue, the second fetch (implicitly executed in line 17) operation fetches the second message in this queue, and so on. Similarly, the first deliver operation (line 31) delivers the first message to the output queue, the second deliver operation (line 31) delivers the second message, and so on.

Roughly speaking, the abstract task of a self-stabilizing alternating-bit (data-link) algorithm $\mathcal{DL}$ is eventually to guarantee exactly-once message delivery without reordering. More formally, there must exist a suffix of the queue of input messages $I = ({im}_j, {im}_{j+1}, ···)$ and a $k$ such that the suffix of the output that starts following the first $k−1$ messages, $O = ({om}_k, {om}_{k+1}, ···)$, is always a prefix of $I$. Furthermore, a new message is included in $O$ infinitely often.

More formally, once the system is in a safe configuration, the value of the labels in the sequence $ \mathcal{L} = {bit}_s, q_{s,r}, {bit}_r, q_{r,s}$ is in $[0^∗ 1^∗, 1^∗ 0^∗]$. Roughly speaking, we say that a single *border* between the labels of value 0 and the labels of value 1 slides from the sender to the receiver and back to the sender. For example, let us consider a particular execution that starts in a configuration with the sequence $0^k$; for some integer $k$, the sender receives a frame with sequence number 0 (acknowledgment) and assigns 1 to ${bit}_s$. The resulting sequence is $\mathcal{L} = 10^{k−2}$. From this configuration, in our particular choice of execution, the sender sends a frame with label 1. At this stage, the sequence is $\mathcal{L} = 1^2 0^{k−2}$. Continuing in the same fashion, we reach a configuration in which $\mathcal{L} = 1^i 0^{k−i}$ for $2 ≤ i ≤ k$. In the particular execution we have chosen, neither retransmission due to timeout and nor message loss occurs. Given a configuration with $\mathcal{L} = x^i (1−x)^j$, where x is either 0 or 1, the sequence $\mathcal{L}$ that is the result of retransmission due to a timeout is $\mathcal{L} = x^{i+1} (1−x)^j$. Similarly, the sequence that is the result of losing a frame with, say, label $(1−x)$ is $\mathcal{L} = x^i (1−x)^{j−1}$.

Let us conclude with the following observation: once a safe configuration is reached, there is at most one *border* in $\mathcal{L}$, where a border is two labels $x$ and $x−1$ that appear one immediately after the other in $\mathcal{L}$.

More than a single border can exist in $\mathcal{L}$ in an arbitrary non-safe configuration. For example, there are eight borders in $\mathcal{L} = 110001001101001$. Denote the sequence $\mathcal{L}$ of the configuration ci by $\mathcal{L}(c_i)$. A loaded configuration $c_i$ is a configuration in which the first and last values in $\mathcal{L}(c_i)$ are equal; for example, $\mathcal{L}(c_i) = 00110001001101000$. Consider all the loaded configurations $c_{i_1}, c_{i_2}, · · ·, c_{i_k}, i_j < i_{j+1}$ in an infinite execution $E$. Note that, in an infinite execution, there must be an infinite number of loaded configurations, since the sender receives infinitely often an acknowledgment with a label equal to ${bit}_s$ .

We next show that the number of borders in $c_{i_{j+1}}$ is less than or equal to the number of borders in $c_{i_j}$. Consider an execution $E'$ that starts in $c_{i_j}$ and ends in $c_{i_{j+1}}$. First let us convince ourselves that any $loss$ operation during $E'$ cannot increase the number of borders. This is clear when the lost frame has at least one neighboring frame with the same label value — the loss of a label from a pair 00 or 11 does not change the number of borders. Moreover, the loss of a frame that has no neighboring frame with the same label value reduces the number of borders. The only step that can increment the number of borders is one in which the sender changes the value of ${bit}_s$. This change increments the number of borders by 1. Without loss of generality, we assume that ${bit}_s = 0$ immediately before the sender changes the value of ${bit}_s$. The sender receives an acknowledgment with label 0 and changes the value of ${bit}_s$ to 1. The value of ${bit}_s$ is 1 until the next loaded configuration is reached; the loaded configuration is reached when the last sequence of frames with label 0 in $\mathcal{L}$ is removed. Therefore, the number of borders is increased by 1 and reduced by 1 because the sender changed the value of ${bit}_s$ between every two successive loaded configurations. We can conclude that the number of borders in the loaded configurations can only be reduced.

This is the key observation for claiming that the alternating-bit algorithm is pseudo self-stabilizing for $\mathcal{DL}$. From any arbitrary configuration, the number of borders in loaded configurations can be reduced only a finite number of times, but there is no limit on the length of the execution for such a reduction to occur. In fact, it is possible that the number of borders in the loaded configurations will be greater than 0 forever.

Let us describe a specific execution in which the number of borders in the loaded configurations is fixed. Starting in a configuration $c$, with $\mathcal{L}= 0^∗ 1^∗ 0^∗$, the sender receives an acknowledgment with label 0, changes the value of ${bit}_s$ to 1, and starts sending the message ${im}_j$ with the label ${bit}_s = 1$. The resulting value of $\mathcal{L}$ is $1 0^∗ 1^∗ 0^∗$. Next the sender receives all the acknowledgments with label 0 until a configuration in which $\mathcal{L} = 1^∗ 0^∗ 1^∗$ is reached. Note that every frame sent following $c$ carries the message ${im}_j$. Let us use the notation $\mathcal{L} = (1, {im}_j)^∗ 0^∗ 1^∗$ to denote that the frames with label 1 in the beginning of $\mathcal{L}$ carries the message ${im}_j$ or an acknowledgment for ${im}_j$. Since the number of borders is not reduced, the value of $\mathcal{L}$ in the next loaded configuration is $\mathcal{L} = (0, {im}_{j+1})^∗ (1, {im}_j)^∗$, $0^∗$ and $\mathcal{L} = (1, {im}_{j+2})^∗ (0, {im}_{j+1})^∗ (1, {im}_j)^∗$ in the following loaded configuration. In such an execution, every input message is output by the receiver exactly once. However, since the number of borders is greater than 0, it is possible that messages will be lost at some point in the execution due to the loss of several frames. For example, if all the frames with label 0 are lost from $\mathcal{L} = (1, {im}_{k+2})^∗ (0, {im}_{k+1})^∗ (1, {im}_k)^∗$ before they reach the receiver, the messages ${im}_{k+1}$ and ${im}_{k+2}$ will be lost, since they have label 1; hence the receiver will not identify these messages as new messages.

To summarize, the alternating-bit algorithm is pseudo self-stabilizing for the data-link task, guaranteeing that the number of messages that are lost during infinite execution is bounded, and the performance between any such two losses is according to the abstract task of the data-link.
